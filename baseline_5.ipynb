{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6n-Ps2nkVsBb"
   },
   "source": [
    "# **ğŸ’ğŸ»ğŸ—¨ï¸ğŸ’ğŸ»â€â™‚ï¸ëŒ€í™” ìš”ì•½ Baseline code**\n",
    "> **Dialogue Summarization** ê²½ì§„ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰    \n",
    "> ë³¸ ëŒ€íšŒì—ì„œëŠ” ìµœì†Œ 2ëª…ì—ì„œ ìµœëŒ€ 7ëª…ì´ ë“±ì¥í•˜ì—¬ ë‚˜ëˆ„ëŠ” ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” BART ê¸°ë°˜ ëª¨ë¸ì˜ baseline codeë¥¼ ì œê³µí•©ë‹ˆë‹¤.     \n",
    "> ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¼ìƒ ëŒ€í™”ì— ëŒ€í•œ ìš”ì•½ì„ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNq_LylZa1ug"
   },
   "source": [
    "## âš™ï¸ ë°ì´í„° ë° í™˜ê²½ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjCiuI_V4glr"
   },
   "source": [
    "### 1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYqDF_-r2ToB"
   },
   "source": [
    "- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œ í›„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### 2) Config file ë§Œë“¤ê¸° (ì„ íƒ)\n",
    "- ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "  ë”°ë¼ì„œ, ì½”ë“œ ìƒì—ì„œ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•  ìˆ˜ë„ ìˆì§€ë§Œ ë…ë¦½ì ì¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm7ob25lHBkR"
   },
   "source": [
    "- ì°¸ê³ âœ…    \n",
    ": wandb ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  entity, project, nameë¥¼ ì§€ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. wandb í™ˆí˜ì´ì§€ì— ê°€ì…í•œ í›„ ì–»ì€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObEASD6Wj6pl"
   },
   "source": [
    "### 3) Configuration ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### 4) ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ í™•ì¸í•´ë³´ê¸°\n",
    "- ì‹¤í—˜ì—ì„œ ì“°ì¼ ë°ì´í„°ë¥¼ loadí•˜ì—¬ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "- Train, dev, test ìˆœì„œëŒ€ë¡œ 12457, 499, 250ê°œ ì”© ë°ì´í„°ê°€ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquriquri7\u001b[0m (\u001b[33mfc_bootcamp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n",
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded config keys:\n",
      "['general', 'inference', 'tokenizer', 'training', 'wandb']\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 1. ë°ì´í„° ë° í™˜ê²½ì„¤ì •\n",
    "# ===============================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BartForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    ")\n",
    "\n",
    "from rouge import Rouge  # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ìš©\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "import wandb  # ì„ íƒ: ì‹¤í—˜ ë¡œê¹…ìš©\n",
    "\n",
    "\n",
    "# ---------- (ì„ íƒ) LoRA ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜: í•„ìš” ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ ----------\n",
    "# !pip install peft accelerate bitsandbytes\n",
    "\n",
    "\n",
    "# ---------- ìš”ì•½ë¬¸ í›„ì²˜ë¦¬ ìœ í‹¸ í•¨ìˆ˜ ----------\n",
    "def clean_generated_summary(summary_list, remove_tokens):\n",
    "    \"\"\"\n",
    "    ìƒì„±ëœ ìš”ì•½ë¬¸ì—ì„œ ë¶ˆí•„ìš”í•œ í† í°ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    escaped_tokens = [re.escape(token) for token in remove_tokens]\n",
    "    pattern = \"|\".join(escaped_tokens)\n",
    "\n",
    "    cleaned_texts = []\n",
    "    for text in summary_list:\n",
    "        cleaned = re.sub(pattern, \" \", text)\n",
    "        cleaned = re.sub(r\"\\s+\", \" \", cleaned)\n",
    "        cleaned = cleaned.strip()\n",
    "        cleaned_texts.append(cleaned)\n",
    "\n",
    "    return cleaned_texts\n",
    "\n",
    "\n",
    "def remove_repeated_ngrams(text, n=3):\n",
    "    \"\"\"\n",
    "    ë¬¸ì¥ ë‚´ì—ì„œ ë°˜ë³µë˜ëŠ” N-gramì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    ì˜ˆ: \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš” ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš”\" â†’ \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš”\"\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    seen = set()\n",
    "    result = []\n",
    "\n",
    "    for i in range(len(tokens)):\n",
    "        ngram = tuple(tokens[i:i+n])\n",
    "\n",
    "        if len(ngram) < n:\n",
    "            result.append(tokens[i])\n",
    "            continue\n",
    "\n",
    "        if ngram not in seen:\n",
    "            seen.add(ngram)\n",
    "            result.append(tokens[i])\n",
    "        else:\n",
    "            # ì¤‘ë³µëœ N-gramì´ë©´ skip\n",
    "            continue\n",
    "\n",
    "    return \" \".join(result)\n",
    "\n",
    "\n",
    "def clean_repetition_in_summaries(summary_list, n=3):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ìš”ì•½ë¬¸ì— ëŒ€í•´ N-gram ë°˜ë³µì„ ì œê±°í•˜ëŠ” wrapper í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    cleaned_list = []\n",
    "    for text in summary_list:\n",
    "        cleaned = remove_repeated_ngrams(text, n=n)\n",
    "        cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "        cleaned_list.append(cleaned)\n",
    "    return cleaned_list\n",
    "\n",
    "\n",
    "# ---------- (ì„ íƒ) wandb ë¡œê·¸ì¸ ----------\n",
    "# ë³´ì•ˆìƒ API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ë‚˜ CLI ë¡œê·¸ì¸ ì‚¬ìš©ì„ ê¶Œì¥\n",
    "# wandb.login()   # CLIì—ì„œ ë¯¸ë¦¬ `wandb login` í•œ ê²½ìš°\n",
    "# ë˜ëŠ”\n",
    "wandb.login(key=\"624410f236117b79b2ee07a4ccef31c7514a5e03\")\n",
    "\n",
    "\n",
    "# ---------- tokenizer ì„  ë¡œë“œ (config ìƒì„±ìš©) ----------\n",
    "base_model_name = \"digit82/kobart-summarization\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"./data/\",                # train.csv, dev.csv, test.csv ìœ„ì¹˜\n",
    "        \"model_name\": base_model_name,         # ì‚¬ìš© ëª¨ë¸\n",
    "        \"output_dir\": \"./prediction/\",         # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        \"special_tokens\": [\n",
    "            \"#Person1#\",\n",
    "            \"#Person2#\",\n",
    "            \"#Person3#\",\n",
    "            \"#PhoneNumber#\",\n",
    "            \"#Address#\",\n",
    "            \"#PassportNumber#\",\n",
    "        ],\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 10,\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"per_device_eval_batch_size\": 8,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": \"cosine\",\n",
    "        \"optim\": \"adamw_torch\",\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"save_strategy\": \"no\",           # HF Trainer ìë™ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ X (LoRAë§Œ ë³„ë„ë¡œ ì €ì¥)\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": False,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\",             # \"wandb\" ë¡œ ë°”ê¾¸ë©´ wandb ì‚¬ìš©\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"fc_bootcamp\",           # ì‚¬ìš©ì ê³„ì •/íŒ€ ì´ë¦„\n",
    "        \"project\": \"nlp\",                # í”„ë¡œì íŠ¸ ì´ë¦„\n",
    "        \"name\": \"run_name\",           # run ì´ë¦„\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"./lora_epoch_20\",   # ì‚¬ìš©í•  LoRA adapter ë””ë ‰í† ë¦¬ (í•™ìŠµ í›„ ìˆ˜ì •)\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 80,\n",
    "        \"num_beams\": 5,\n",
    "        \"batch_size\": 32,\n",
    "        \"remove_tokens\": [\n",
    "            \"<usr>\",\n",
    "            f\"{tokenizer.bos_token}\",\n",
    "            f\"{tokenizer.eos_token}\",\n",
    "            f\"{tokenizer.pad_token}\",\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "# ---------- YAMLë¡œ ì €ì¥ ----------\n",
    "os.makedirs(\"config\", exist_ok=True)\n",
    "config_path = \"config/config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "\n",
    "# ---------- YAML ë¡œë“œ ----------\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "print(\"âœ… Loaded config keys:\")\n",
    "pprint(list(loaded_config.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "## 1. ë°ì´í„° ê°€ê³µ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬ì¶•\n",
    "- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•´ì¤ë‹ˆë‹¤.\n",
    "- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 2. ë°ì´í„° ê°€ê³µ ë° Dataset í´ë˜ìŠ¤\n",
    "# ===============================\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, bos_token: str, eos_token: str, max_turns: int = 12):\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.max_turns = max_turns\n",
    "\n",
    "    @staticmethod\n",
    "    def make_set_as_df(file_path, is_train: bool = True):\n",
    "        df = pd.read_csv(file_path)\n",
    "        if is_train:\n",
    "            return df[[\"fname\", \"dialogue\", \"summary\"]]\n",
    "        else:\n",
    "            return df[[\"fname\", \"dialogue\"]]\n",
    "\n",
    "    def _trim_dialogue(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        1) ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ í„´ ë‚˜ëˆ„ê¸°\n",
    "        2) ë§ˆì§€ë§‰ max_turns ê°œë§Œ ì‚¬ìš©\n",
    "        3) ë„ˆë¬´ ì§§ì€ filler í„´ì€ ì œê±°\n",
    "        \"\"\"\n",
    "        turns = text.split(\"\\n\")\n",
    "\n",
    "        # ë§ˆì§€ë§‰ max_turnsë§Œ ì‚¬ìš©\n",
    "        if len(turns) > self.max_turns:\n",
    "            turns = turns[-self.max_turns:]\n",
    "\n",
    "        cleaned = []\n",
    "        for t in turns:\n",
    "            t_strip = t.strip()\n",
    "            if len(t_strip) < 3:\n",
    "                continue\n",
    "            # í”í•œ filler ëª‡ ê°œ ì œê±° ì˜ˆì‹œ (í•„ìš”ì‹œ ë” ì¶”ê°€)\n",
    "            if t_strip in [\"ë„¤\", \"ë„¤ë„¤\", \"ì˜ˆ\", \"ì•Œê² ìŠµë‹ˆë‹¤\", \"ë„¤, ì•Œê² ìŠµë‹ˆë‹¤\"]:\n",
    "                continue\n",
    "            cleaned.append(t_strip)\n",
    "\n",
    "        return \"\\n\".join(cleaned)\n",
    "\n",
    "    def make_input(self, dataset, is_test: bool = False):\n",
    "        dialogues = dataset[\"dialogue\"].apply(self._trim_dialogue)\n",
    "\n",
    "        if is_test:\n",
    "            encoder_input = dialogues\n",
    "            decoder_input = [self.bos_token] * len(dialogues)\n",
    "            return encoder_input.tolist(), decoder_input\n",
    "        else:\n",
    "            encoder_input = dialogues\n",
    "            decoder_input = dataset[\"summary\"].apply(\n",
    "                lambda x: self.bos_token + str(x)\n",
    "            )\n",
    "            decoder_output = dataset[\"summary\"].apply(\n",
    "                lambda x: str(x) + self.eos_token\n",
    "            )\n",
    "            return (\n",
    "                encoder_input.tolist(),\n",
    "                decoder_input.tolist(),\n",
    "                decoder_output.tolist(),\n",
    "            )\n",
    "\n",
    "\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Train / Validation ê³µìš© Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_input, decoder_input, labels, length: int):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # encoder\n",
    "        item = {\n",
    "            key: val[idx].clone().detach()\n",
    "            for key, val in self.encoder_input.items()\n",
    "        }  # input_ids, attention_mask\n",
    "\n",
    "        # decoder\n",
    "        dec = {\n",
    "            key: val[idx].clone().detach()\n",
    "            for key, val in self.decoder_input.items()\n",
    "        }  # input_ids, attention_mask\n",
    "        dec[\"decoder_input_ids\"] = dec[\"input_ids\"]\n",
    "        dec[\"decoder_attention_mask\"] = dec[\"attention_mask\"]\n",
    "        dec.pop(\"input_ids\")\n",
    "        dec.pop(\"attention_mask\")\n",
    "\n",
    "        item.update(dec)\n",
    "        item[\"labels\"] = self.labels[\"input_ids\"][idx]  # teacher forcing labels\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "class DatasetForInference(Dataset):\n",
    "    \"\"\"\n",
    "    Testìš© Dataset (encoder ì…ë ¥ + fname)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_input, test_id, length: int):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.length = length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            key: val[idx].clone().detach()\n",
    "            for key, val in self.encoder_input.items()\n",
    "        }\n",
    "        item[\"ID\"] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "def prepare_train_dataset(config, preprocessor: Preprocess, data_path: str, tokenizer):\n",
    "    \"\"\"\n",
    "    train / dev CSVë¥¼ ì½ì–´ì„œ tokenizationê¹Œì§€ ì™„ë£Œí•œ Dataset ë°˜í™˜\n",
    "    \"\"\"\n",
    "    train_file_path = os.path.join(data_path, \"train.csv\")\n",
    "    val_file_path = os.path.join(data_path, \"dev.csv\")\n",
    "\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path, is_train=True)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path, is_train=True)\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "    encoder_input_train, decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val, decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "\n",
    "    print(\"âœ… Load raw data complete\")\n",
    "\n",
    "    # tokenization\n",
    "    tokenized_encoder_inputs = tokenizer(\n",
    "        encoder_input_train,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=config[\"tokenizer\"][\"encoder_max_len\"],\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    tokenized_decoder_inputs = tokenizer(\n",
    "        decoder_input_train,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=config[\"tokenizer\"][\"decoder_max_len\"],\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    tokenized_decoder_outputs = tokenizer(\n",
    "        decoder_output_train,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=config[\"tokenizer\"][\"decoder_max_len\"],\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "    train_dataset = Seq2SeqDataset(\n",
    "        tokenized_encoder_inputs,\n",
    "        tokenized_decoder_inputs,\n",
    "        tokenized_decoder_outputs,\n",
    "        len(encoder_input_train),\n",
    "    )\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(\n",
    "        encoder_input_val,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=config[\"tokenizer\"][\"encoder_max_len\"],\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    val_tokenized_decoder_inputs = tokenizer(\n",
    "        decoder_input_val,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=config[\"tokenizer\"][\"decoder_max_len\"],\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "    val_tokenized_decoder_outputs = tokenizer(\n",
    "        decoder_output_val,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=config[\"tokenizer\"][\"decoder_max_len\"],\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "    val_dataset = Seq2SeqDataset(\n",
    "        val_tokenized_encoder_inputs,\n",
    "        val_tokenized_decoder_inputs,\n",
    "        val_tokenized_decoder_outputs,\n",
    "        len(encoder_input_val),\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Make train / val dataset complete\")\n",
    "    return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "## 2. Trainer ë° Trainingargs êµ¬ì¶•í•˜ê¸°\n",
    "- Huggingface ì˜ Trainer ì™€ Training argumentsë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3. Trainer ë° TrainingArguments\n",
    "# ===============================\n",
    "\n",
    "def compute_metrics(config, tokenizer, pred):\n",
    "    \"\"\"\n",
    "    Rouge ê¸°ë°˜ í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "    - ì „ì²˜ë¦¬ í›„ ë¹ˆ ë¬¸ìì—´ì´ ë˜ëŠ” ì˜ˆì¸¡/ì •ë‹µ ìŒì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    # -100 â†’ pad_token_idë¡œ ë³µì›\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(\n",
    "        predictions, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "    decoded_labels = tokenizer.batch_decode(\n",
    "        labels, clean_up_tokenization_spaces=True\n",
    "    )\n",
    "\n",
    "    # ë¶ˆí•„ìš”í•œ í† í° ì œê±°\n",
    "    remove_tokens = config[\"inference\"][\"remove_tokens\"]\n",
    "\n",
    "    def clean_text_list(text_list):\n",
    "        out = []\n",
    "        for s in text_list:\n",
    "            for token in remove_tokens:\n",
    "                s = s.replace(token, \" \")\n",
    "            s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "            out.append(s)\n",
    "        return out\n",
    "\n",
    "    replaced_predictions = clean_text_list(decoded_preds)\n",
    "    replaced_labels = clean_text_list(decoded_labels)\n",
    "\n",
    "    # --- ë¹ˆ ë¬¸ìì—´ ì•ˆì „ ì²˜ë¦¬ ---\n",
    "    pairs = []\n",
    "    for p, l in zip(replaced_predictions, replaced_labels):\n",
    "        # ì˜ˆì¸¡/ì •ë‹µì´ ë‘˜ ë‹¤ ì™„ì „íˆ ë¹„ì–´ ìˆìœ¼ë©´ ìŠ¤í‚µ\n",
    "        if (not p.strip()) and (not l.strip()):\n",
    "            continue\n",
    "\n",
    "        # ì˜ˆì¸¡ì´ ë¹„ì–´ ìˆìœ¼ë©´ ìµœì†Œ ë”ë¯¸ í† í° í•˜ë‚˜ ë„£ì–´ì¤Œ\n",
    "        if not p.strip():\n",
    "            p = \".\"\n",
    "\n",
    "        # ì •ë‹µì´ ë¹„ì–´ ìˆì„ ì¼ì€ ê±°ì˜ ì—†ì§€ë§Œ ë°©ì–´ì ìœ¼ë¡œ ì²˜ë¦¬\n",
    "        if not l.strip():\n",
    "            l = \".\"\n",
    "\n",
    "        pairs.append((p, l))\n",
    "\n",
    "    if len(pairs) == 0:\n",
    "        # ì „ë¶€ ë¹„ì–´ ìˆëŠ” ê·¹ë‹¨ì  ì¼€ì´ìŠ¤ë¼ë©´ 0ì  ë¦¬í„´\n",
    "        return {\"rouge-1\": 0.0, \"rouge-2\": 0.0, \"rouge-l\": 0.0}\n",
    "\n",
    "    preds_clean, labels_clean = zip(*pairs)\n",
    "    preds_clean = list(preds_clean)\n",
    "    labels_clean = list(labels_clean)\n",
    "\n",
    "    # ëª¨ë‹ˆí„°ë§ìš©ìœ¼ë¡œ ì²« ìƒ˜í”Œ ì¶œë ¥\n",
    "    print(\"-\" * 120)\n",
    "    print(f\"PRED[0]: {preds_clean[0]}\")\n",
    "    print(f\"GOLD[0]: {labels_clean[0]}\")\n",
    "\n",
    "    # ROUGE ì ìˆ˜ ê³„ì‚° (avg=True)\n",
    "    results = rouge.get_scores(preds_clean, labels_clean, avg=True)\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_training_args(config):\n",
    "    \"\"\"\n",
    "    HF Trainer ìš© TrainingArguments ìƒì„±\n",
    "    - ì‹¤ì œ epoch ë£¨í”„ëŠ” ë°”ê¹¥(main)ì—ì„œ ëŒë¦¬ë¯€ë¡œ num_train_epochs=1 ê³ ì •\n",
    "    \"\"\"\n",
    "    return Seq2SeqTrainingArguments(\n",
    "        output_dir=config[\"general\"][\"output_dir\"],\n",
    "        overwrite_output_dir=config[\"training\"][\"overwrite_output_dir\"],\n",
    "        num_train_epochs=1,  # í•œ ë²ˆ train() í˜¸ì¶œ ì‹œ 1 epochë§Œ\n",
    "        learning_rate=config[\"training\"][\"learning_rate\"],\n",
    "        per_device_train_batch_size=config[\"training\"][\"per_device_train_batch_size\"],\n",
    "        per_device_eval_batch_size=config[\"training\"][\"per_device_eval_batch_size\"],\n",
    "        warmup_ratio=config[\"training\"][\"warmup_ratio\"],\n",
    "        weight_decay=config[\"training\"][\"weight_decay\"],\n",
    "        lr_scheduler_type=config[\"training\"][\"lr_scheduler_type\"],\n",
    "        evaluation_strategy=config[\"training\"][\"evaluation_strategy\"],\n",
    "        save_strategy=config[\"training\"][\"save_strategy\"],  # \"no\"\n",
    "        save_total_limit=config[\"training\"][\"save_total_limit\"],\n",
    "        load_best_model_at_end=config[\"training\"][\"load_best_model_at_end\"],\n",
    "        logging_dir=config[\"training\"][\"logging_dir\"],\n",
    "        logging_strategy=config[\"training\"][\"logging_strategy\"],\n",
    "        predict_with_generate=config[\"training\"][\"predict_with_generate\"],\n",
    "        generation_max_length=config[\"training\"][\"generation_max_length\"],\n",
    "        fp16=config[\"training\"][\"fp16\"],\n",
    "        save_safetensors=True,\n",
    "        seed=config[\"training\"][\"seed\"],\n",
    "        report_to=config[\"training\"][\"report_to\"],  # \"none\" ë˜ëŠ” \"wandb\"\n",
    "        gradient_accumulation_steps=config[\"training\"][\"gradient_accumulation_steps\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_lora_to_model(model):\n",
    "    \"\"\"\n",
    "    KoBARTì— LoRA ì£¼ì…\n",
    "    \"\"\"\n",
    "    lora_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_2_SEQ_LM\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer_and_model_for_train(config, device):\n",
    "    \"\"\"\n",
    "    í•™ìŠµìš© KoBART + LoRA ëª¨ë¸ ë¡œë”\n",
    "    \"\"\"\n",
    "    print(\"---------- Load tokenizer & model with LoRA ----------\")\n",
    "\n",
    "    model_name = config[\"general\"][\"model_name\"]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # special tokens ì¶”ê°€\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": config[\"tokenizer\"][\"special_tokens\"]}\n",
    "    )\n",
    "\n",
    "    # base BART model load\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # LoRA ì ìš©\n",
    "    model = apply_lora_to_model(model)\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"âœ… Model config:\")\n",
    "    print(model.config)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def build_trainer(model, tokenizer, train_ds, val_ds, config):\n",
    "    \"\"\"\n",
    "    Seq2SeqTrainer ìƒì„±\n",
    "    - ë‚´ë¶€ save_modelì€ ë§‰ê³ , LoRA adapterëŠ” ë³„ë„ í•¨ìˆ˜ì—ì„œ ì €ì¥\n",
    "    \"\"\"\n",
    "    training_args = build_training_args(config)\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),\n",
    "    )\n",
    "\n",
    "    # HF Trainer ê¸°ë³¸ save_model ê¸°ëŠ¥ ë¬´ë ¥í™” (shared weight error ë°©ì§€)\n",
    "    trainer.save_model = lambda *args, **kwargs: None\n",
    "\n",
    "    return trainer\n",
    "\n",
    "\n",
    "def save_lora_adapter(model, epoch: int):\n",
    "    \"\"\"\n",
    "    epochë³„ LoRA adapterë§Œ ì €ì¥\n",
    "    \"\"\"\n",
    "    save_dir = f\"./lora_epoch_{epoch}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.save_pretrained(save_dir)\n",
    "    print(f\"ğŸ’¾ Saved LoRA adapter: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "## 3. ëª¨ë¸ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZUb-BC42J-"
   },
   "source": [
    "- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device: cuda ----------\n",
      "2.1.2+cu118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/nlp_server/wandb/run-20251201_113332-g4dyvgix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fc_bootcamp/nlp/runs/g4dyvgix' target=\"_blank\">run_name</a></strong> to <a href='https://wandb.ai/fc_bootcamp/nlp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fc_bootcamp/nlp' target=\"_blank\">https://wandb.ai/fc_bootcamp/nlp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fc_bootcamp/nlp/runs/g4dyvgix' target=\"_blank\">https://wandb.ai/fc_bootcamp/nlp/runs/g4dyvgix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Load tokenizer & model with LoRA ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 124,749,312 || trainable%: 0.7092\n",
      "âœ… Model config:\n",
      "BartConfig {\n",
      "  \"_name_or_path\": \"digit82/kobart-summarization\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30006\n",
      "}\n",
      "\n",
      "âœ… Load raw data complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Make train / val dataset complete\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 1/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.302400</td>\n",
       "      <td>3.892373</td>\n",
       "      <td>0.260065</td>\n",
       "      <td>0.091374</td>\n",
       "      <td>0.242488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 1 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_1\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 2/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.872400</td>\n",
       "      <td>3.859959</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.104679</td>\n",
       "      <td>0.261465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 2 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_2\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 3/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.845900</td>\n",
       "      <td>3.845757</td>\n",
       "      <td>0.283941</td>\n",
       "      <td>0.109029</td>\n",
       "      <td>0.265791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 3 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_3\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 4/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:55, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.829700</td>\n",
       "      <td>3.836822</td>\n",
       "      <td>0.288062</td>\n",
       "      <td>0.111748</td>\n",
       "      <td>0.268669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸¸ ë¶€íƒí•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 4 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_4\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 5/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.817400</td>\n",
       "      <td>3.830590</td>\n",
       "      <td>0.287497</td>\n",
       "      <td>0.112150</td>\n",
       "      <td>0.269549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸¸ ìš”ì²­í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 5 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_5\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 6/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.807400</td>\n",
       "      <td>3.825968</td>\n",
       "      <td>0.293366</td>\n",
       "      <td>0.115817</td>\n",
       "      <td>0.274215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸¸ ìš”ì²­í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 6 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_6\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 7/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.798800</td>\n",
       "      <td>3.822410</td>\n",
       "      <td>0.299639</td>\n",
       "      <td>0.120386</td>\n",
       "      <td>0.280629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸¸ ê¶Œìœ í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 7 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_7\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 8/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.791200</td>\n",
       "      <td>3.819595</td>\n",
       "      <td>0.298450</td>\n",
       "      <td>0.119772</td>\n",
       "      <td>0.279910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸¸ ê¶Œìœ í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 8 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_8\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 9/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.784200</td>\n",
       "      <td>3.817473</td>\n",
       "      <td>0.299759</td>\n",
       "      <td>0.118448</td>\n",
       "      <td>0.279533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸¸ ê¶Œìœ í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 9 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_9\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 10/10 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3115' max='3115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3115/3115 02:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.777800</td>\n",
       "      <td>3.815823</td>\n",
       "      <td>0.301224</td>\n",
       "      <td>0.120251</td>\n",
       "      <td>0.281169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "PRED[0]: #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸¸ ê¶Œìœ í•©ë‹ˆë‹¤.\n",
      "GOLD[0]: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Epoch 10 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved LoRA adapter: ./lora_epoch_10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21bf136bae44b67842d8e7a17f50481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1792.121 MB of 1792.121 MB uploaded (0.089 MB deduped)\\r'), FloatProgress(value=1.â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>eval/rouge-1</td><td>â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/rouge-2</td><td>â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/rouge-l</td><td>â–â–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/runtime</td><td>â–ˆâ–â–ƒâ–…â–…â–…â–„â–…â–…â–†</td></tr><tr><td>eval/samples_per_second</td><td>â–â–ˆâ–†â–„â–„â–„â–…â–„â–ƒâ–ƒ</td></tr><tr><td>eval/steps_per_second</td><td>â–â–ˆâ–†â–„â–„â–„â–…â–„â–ƒâ–ƒ</td></tr><tr><td>train/epoch</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/global_step</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>train/total_flos</td><td>â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/train_loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>train/train_runtime</td><td>â–†â–â–…â–ƒâ–…â–…â–…â–‡â–ˆâ–†</td></tr><tr><td>train/train_samples_per_second</td><td>â–ƒâ–ˆâ–„â–…â–„â–„â–„â–‚â–â–ƒ</td></tr><tr><td>train/train_steps_per_second</td><td>â–ƒâ–ˆâ–„â–…â–„â–„â–„â–‚â–â–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.81582</td></tr><tr><td>eval/rouge-1</td><td>0.30122</td></tr><tr><td>eval/rouge-2</td><td>0.12025</td></tr><tr><td>eval/rouge-l</td><td>0.28117</td></tr><tr><td>eval/runtime</td><td>20.366</td></tr><tr><td>eval/samples_per_second</td><td>24.502</td></tr><tr><td>eval/steps_per_second</td><td>3.093</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>3115</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.7778</td></tr><tr><td>train/total_flos</td><td>3831600522461184.0</td></tr><tr><td>train/train_loss</td><td>3.77783</td></tr><tr><td>train/train_runtime</td><td>175.5365</td></tr><tr><td>train/train_samples_per_second</td><td>70.965</td></tr><tr><td>train/train_steps_per_second</td><td>17.746</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_name</strong> at: <a href='https://wandb.ai/fc_bootcamp/nlp/runs/g4dyvgix' target=\"_blank\">https://wandb.ai/fc_bootcamp/nlp/runs/g4dyvgix</a><br/>Synced 5 W&B file(s), 0 media file(s), 40 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251201_113332-g4dyvgix/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================\n",
    "# 4. ëª¨ë¸ í•™ìŠµí•˜ê¸°\n",
    "# ===============================\n",
    "\n",
    "def main(config):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"---------- device:\", device, \"----------\")\n",
    "    print(torch.__version__)\n",
    "\n",
    "    # (ì„ íƒ) wandb í™œì„±í™” ì‹œ\n",
    "    if config[\"training\"][\"report_to\"] == \"wandb\":\n",
    "        wandb.init(\n",
    "            entity=config[\"wandb\"][\"entity\"],\n",
    "            project=config[\"wandb\"][\"project\"],\n",
    "            name=config[\"wandb\"][\"name\"],\n",
    "        )\n",
    "        os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n",
    "        os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "    else:\n",
    "        os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "        print(\"ğŸš« wandb ë¹„í™œì„±í™” ìƒíƒœë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    # 1) ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë“œ (LoRA ì ìš©)\n",
    "    model, tokenizer = load_tokenizer_and_model_for_train(config, device)\n",
    "\n",
    "    # 2) ë°ì´í„° ë¡œë“œ\n",
    "    preprocessor = Preprocess(\n",
    "        config[\"tokenizer\"][\"bos_token\"], config[\"tokenizer\"][\"eos_token\"], max_turns=12,  # â† ì—¬ê¸° ìˆ«ìë§Œ ë°”ê¿”ê°€ë©° ì‹¤í—˜ (10~14 ì¶”ì²œ)\n",
    "    )\n",
    "    train_ds, val_ds = prepare_train_dataset(\n",
    "        config, preprocessor, config[\"general\"][\"data_path\"], tokenizer\n",
    "    )\n",
    "\n",
    "    # 3) Trainer ìƒì„±\n",
    "    trainer = build_trainer(model, tokenizer, train_ds, val_ds, config)\n",
    "\n",
    "    # 4) epoch ë£¨í”„\n",
    "    total_epoch = config[\"training\"][\"num_train_epochs\"]\n",
    "\n",
    "    for epoch in range(total_epoch):\n",
    "        print(f\"\\n\\nğŸ”¥ğŸ”¥ğŸ”¥ EPOCH {epoch + 1}/{total_epoch} ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\")\n",
    "        trainer.train()\n",
    "        print(f\"ğŸ”¥ Epoch {epoch + 1} ì¢…ë£Œ\")\n",
    "\n",
    "        # LoRA adapter ì €ì¥\n",
    "        save_lora_adapter(model, epoch + 1)\n",
    "\n",
    "    if config[\"training\"][\"report_to\"] == \"wandb\":\n",
    "        wandb.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "## 4. ëª¨ë¸ ì¶”ë¡ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFGul3-rSscf"
   },
   "source": [
    "- test dataë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda ----------\n",
      "2.1.2+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded LoRA model from: ./lora_epoch_20\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "test_data[0]:\n",
      "#Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \n",
      "#Person2#: ë„¤, ë§ì”€í•˜ì„¸ìš”... \n",
      "#Person1#: ì´ê±¸ ì˜¤ëŠ˜ ì˜¤í›„ê¹Œì§€ ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¡œ ë³´ë‚´ì•¼ í•´ìš”. ì¤€ë¹„ëë‚˜ìš”? \n",
      "#Person2#: ë„¤, ë§ì”€í•˜ì„¸ìš”. \n",
      "#Person1#: ëª¨ë“  ì§ì›ì—ê²Œ ì•Œë¦½ë‹ˆë‹¤... ì¦‰ì‹œ ë°œíš¨ë˜ì–´ ëª¨ë“  ì‚¬ë‚´ í†µì‹ ì€ ì´ë©”ì¼ê³¼ ê³µì‹ ë©”ëª¨ë¡œë§Œ ì œí•œë©ë‹ˆë‹¤. ê·¼ë¬´ ì‹œê°„ ë™ì•ˆ ì¦‰ì‹œ ë©”ì‹œì§€ í”„ë¡œê·¸ë¨ ì‚¬ìš©ì€ ê¸ˆì§€ë©ë‹ˆë‹¤. \n",
      "#Person2#: ì´ ì •ì±…ì´ ì‚¬ë‚´ í†µì‹ ì—ë§Œ ì ìš©ë˜ë‚˜ìš”, ì•„ë‹ˆë©´ ì™¸ë¶€ í†µì‹ ì—ë„ í•´ë‹¹ë˜ë‚˜ìš”? \n",
      "#Person1#: ì´ëŠ” ëª¨ë“  í†µì‹ ì— ì ìš©ë©ë‹ˆë‹¤. ì‚¬ë¬´ì‹¤ ë‚´ ì§ì› ê°„ í†µì‹  ë¿ë§Œ ì•„ë‹ˆë¼ ì™¸ë¶€ í†µì‹ ë„ í•´ë‹¹ë©ë‹ˆë‹¤. \n",
      "#Person2#: í•˜ì§€ë§Œ ë§ì€ ì§ì›ë“¤ì´ ê³ ê°ê³¼ ì†Œí†µí•˜ë ¤ê³  ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. \n",
      "#Person1#: í†µì‹  ë°©ë²•ì„ ë°”ê¿”ì•¼ í•  ê²ƒì…ë‹ˆë‹¤. ì´ ì‚¬ë¬´ì‹¤ì—ì„œëŠ” ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ ì‹œê°„ì´ ë‚­ë¹„ë©ë‹ˆë‹¤! ì´ì œ ê³„ì†í•´ì„œ ë©”ëª¨ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. ì–´ë””ê¹Œì§€ í–ˆì£ ? \n",
      "#Person2#: ë‚´ì™¸ë¶€ í†µì‹ ì— ì ìš©ë©ë‹ˆë‹¤. \n",
      "#Person1#: ë„¤. ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ê³„ì† ì‚¬ìš©í•˜ë©´ ê²½ê³  í›„ ì‹œì • ì¡°ì¹˜ê°€ ì´ë£¨ì–´ì§€ë©°, ë‘ ë²ˆì§¸ ìœ„ë°˜ ì‹œ í•´ê³ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì •ì±…ì— ê´€í•œ ì§ˆë¬¸ì€ ë¶€ì„œì¥ì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”. \n",
      "#Person2#: ê·¸ê²Œ ë‹¤ì¸ê°€ìš”? \n",
      "#Person1#: ë„¤. ì˜¤ëŠ˜ ì˜¤í›„ 4ì‹œê¹Œì§€ ì´ ë©”ëª¨ë¥¼ ì‘ì„±í•˜ê³  ë°°í¬í•´ì£¼ì„¸ìš”.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "âœ… Load test data complete\n",
      "âœ… Make test dataset complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:24<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved inference result to: ./prediction/output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 5. ëª¨ë¸ ì¶”ë¡ í•˜ê¸°\n",
    "# ===============================\n",
    "\n",
    "def prepare_test_dataset(config, preprocessor: Preprocess, tokenizer):\n",
    "    \"\"\"\n",
    "    test.csv â†’ tokenizationê¹Œì§€ ì™„ë£Œí•œ Dataset ë°˜í™˜\n",
    "    \"\"\"\n",
    "    test_file_path = os.path.join(config[\"general\"][\"data_path\"], \"test.csv\")\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path, is_train=False)\n",
    "    test_id = test_data[\"fname\"]\n",
    "\n",
    "    print(\"-\" * 120)\n",
    "    print(f\"test_data[0]:\\n{test_data['dialogue'][0]}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    encoder_input_test, decoder_input_test = preprocessor.make_input(\n",
    "        test_data, is_test=True\n",
    "    )\n",
    "    print(\"âœ… Load test data complete\")\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(\n",
    "        encoder_input_test,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=config[\"tokenizer\"][\"encoder_max_len\"],\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "    test_dataset = DatasetForInference(\n",
    "        test_tokenized_encoder_inputs, test_id, len(encoder_input_test)\n",
    "    )\n",
    "    print(\"âœ… Make test dataset complete\")\n",
    "\n",
    "    return test_data, test_dataset\n",
    "\n",
    "\n",
    "def load_lora_model_for_inference(config, device):\n",
    "    \"\"\"\n",
    "    ì¶”ë¡ ìš©: base KoBART + í•™ìŠµëœ LoRA adapter ë¡œë“œ\n",
    "    \"\"\"\n",
    "    base_model_name = config[\"general\"][\"model_name\"]\n",
    "    lora_path = config[\"inference\"][\"ckt_path\"]\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": config[\"tokenizer\"][\"special_tokens\"]}\n",
    "    )\n",
    "\n",
    "    # base model\n",
    "    base_model = BartForConditionalGeneration.from_pretrained(base_model_name)\n",
    "    base_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # LoRA adapter ë¡œë“œ\n",
    "    model = PeftModel.from_pretrained(base_model, lora_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"âœ… Loaded LoRA model from: {lora_path}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def inference(config):\n",
    "    \"\"\"\n",
    "    í•™ìŠµëœ LoRA ëª¨ë¸ë¡œ test.csv ìš”ì•½ ìƒì„± ë° output.csv ì €ì¥\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"-\" * 10, f\"device : {device}\", \"-\" * 10)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model, tokenizer = load_lora_model_for_inference(config, device)\n",
    "\n",
    "    preprocessor = Preprocess(\n",
    "        config[\"tokenizer\"][\"bos_token\"], config[\"tokenizer\"][\"eos_token\"]\n",
    "    )\n",
    "    test_data, test_dataset = prepare_test_dataset(\n",
    "        config, preprocessor, tokenizer\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        test_dataset, batch_size=config[\"inference\"][\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    summary_list = []\n",
    "    text_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            input_ids = item[\"input_ids\"].to(device)\n",
    "            attention_mask = item[\"attention_mask\"].to(device)\n",
    "            text_ids.extend(item[\"ID\"])\n",
    "\n",
    "            generated_ids = generate_model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                no_repeat_ngram_size=config[\"inference\"][\"no_repeat_ngram_size\"],\n",
    "                early_stopping=config[\"inference\"][\"early_stopping\"],\n",
    "                max_length=config[\"inference\"][\"generate_max_length\"],\n",
    "                num_beams=config[\"inference\"][\"num_beams\"],\n",
    "                min_length=25,          # ìš”ì•½ì´ ë„ˆë¬´ ì§§ì•„ì§€ëŠ” ê²ƒ ë°©ì§€\n",
    "                length_penalty=1.1,     # ì‚´ì§ ê¸¸ì´ íŒ¨ë„í‹° ë¶€ì—¬\n",
    "            )\n",
    "\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids, skip_special_tokens=False)\n",
    "                summary_list.append(result)\n",
    "\n",
    "    # 1ì°¨: ìŠ¤í˜ì…œ í† í° ì œê±°\n",
    "    remove_tokens = config[\"inference\"][\"remove_tokens\"]\n",
    "    preprocessed_summary = clean_generated_summary(summary_list, remove_tokens)\n",
    "\n",
    "    # 2ì°¨: ë°˜ë³µ N-gram ì œê±°\n",
    "    preprocessed_summary = clean_repetition_in_summaries(\n",
    "        preprocessed_summary, n=3\n",
    "    )\n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data[\"fname\"],\n",
    "            \"summary\": preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result_path = config[\"inference\"][\"result_path\"]\n",
    "    os.makedirs(result_path, exist_ok=True)\n",
    "    save_path = os.path.join(result_path, \"output.csv\")\n",
    "    output.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"âœ… Saved inference result to: {save_path}\")\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)\n",
    "    output.head()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
