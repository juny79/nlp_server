{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6n-Ps2nkVsBb"
   },
   "source": [
    "# **ğŸ’ğŸ»ğŸ—¨ï¸ğŸ’ğŸ»â€â™‚ï¸ëŒ€í™” ìš”ì•½ Baseline code**\n",
    "> **Dialogue Summarization** ê²½ì§„ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰    \n",
    "> ë³¸ ëŒ€íšŒì—ì„œëŠ” ìµœì†Œ 2ëª…ì—ì„œ ìµœëŒ€ 7ëª…ì´ ë“±ì¥í•˜ì—¬ ë‚˜ëˆ„ëŠ” ëŒ€í™”ë¥¼ ìš”ì•½í•˜ëŠ” BART ê¸°ë°˜ ëª¨ë¸ì˜ baseline codeë¥¼ ì œê³µí•©ë‹ˆë‹¤.     \n",
    "> ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¼ìƒ ëŒ€í™”ì— ëŒ€í•œ ìš”ì•½ì„ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNq_LylZa1ug"
   },
   "source": [
    "## âš™ï¸ ë°ì´í„° ë° í™˜ê²½ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjCiuI_V4glr"
   },
   "source": [
    "### 1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYqDF_-r2ToB"
   },
   "source": [
    "- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œ í›„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "zbZ7SU9P2TYN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from rouge import Rouge # ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import wandb # ëª¨ë¸ í•™ìŠµ ê³¼ì •ì„ ì†ì‰½ê²Œ Trackingí•˜ê³ , ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in ./venv310/lib/python3.10/site-packages (0.11.1)\n",
      "Requirement already satisfied: accelerate in ./venv310/lib/python3.10/site-packages (0.29.3)\n",
      "Requirement already satisfied: bitsandbytes in ./venv310/lib/python3.10/site-packages (0.41.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv310/lib/python3.10/site-packages (from peft) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv310/lib/python3.10/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in ./venv310/lib/python3.10/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in ./venv310/lib/python3.10/site-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./venv310/lib/python3.10/site-packages (from peft) (2.1.2+cu118)\n",
      "Requirement already satisfied: transformers in ./venv310/lib/python3.10/site-packages (from peft) (4.35.2)\n",
      "Requirement already satisfied: tqdm in ./venv310/lib/python3.10/site-packages (from peft) (4.66.1)\n",
      "Requirement already satisfied: safetensors in ./venv310/lib/python3.10/site-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in ./venv310/lib/python3.10/site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in ./venv310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2025.10.0)\n",
      "Requirement already satisfied: requests in ./venv310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (1.2.0)\n",
      "Requirement already satisfied: sympy in ./venv310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./venv310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./venv310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv310/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv310/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv310/lib/python3.10/site-packages (from transformers->peft) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv310/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ”¥ LoRA(PEFT) ì„¤ì¹˜ & Import\n",
    "# ============================================================\n",
    "!pip install peft accelerate bitsandbytes\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# ğŸ”¼ ì—¬ê¸°: import êµ¬ë¬¸ ë°”ë¡œ ì•„ë˜ì— ì‚½ì…\n",
    "# ===========================================================\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_generated_summary(summary_list, remove_tokens):\n",
    "    escaped_tokens = [re.escape(token) for token in remove_tokens]\n",
    "    pattern = \"|\".join(escaped_tokens)\n",
    "\n",
    "    cleaned_texts = []\n",
    "    for text in summary_list:\n",
    "        cleaned = re.sub(pattern, \" \", text)\n",
    "        cleaned = re.sub(r\"\\s+\", \" \", cleaned)\n",
    "        cleaned = cleaned.strip()\n",
    "        cleaned_texts.append(cleaned)\n",
    "\n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ”¥ N-gram ë°˜ë³µ ì œê±° í•¨ìˆ˜ (ìš”ì•½ë¬¸ í’ˆì§ˆ ê°œì„ )\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_repeated_ngrams(text, n=3):\n",
    "    \"\"\"\n",
    "    ë¬¸ì¥ ë‚´ì—ì„œ ë°˜ë³µë˜ëŠ” N-gramì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜.\n",
    "    ì˜ˆ: \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš” ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš”\" â†’ \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ìš”\"\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    seen = set()\n",
    "    result = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        # í˜„ì¬ N-gram ì¶”ì¶œ\n",
    "        ngram = tuple(tokens[i:i+n])\n",
    "        \n",
    "        if len(ngram) < n:\n",
    "            # ë§ˆì§€ë§‰ ë¶€ë¶„ ë‹¨ì–´ëŠ” ê·¸ëŒ€ë¡œ ì¶”ê°€\n",
    "            result.append(tokens[i])\n",
    "            continue\n",
    "        \n",
    "        # N-gram ë°˜ë³µ ì—¬ë¶€ í™•ì¸\n",
    "        if ngram not in seen:\n",
    "            seen.add(ngram)\n",
    "            result.append(tokens[i])\n",
    "        else:\n",
    "            # ì¤‘ë³µëœ N-gramì´ë©´ skip\n",
    "            continue\n",
    "\n",
    "    # ì •ë¦¬ëœ ë¬¸ì¥ ë°˜í™˜\n",
    "    return \" \".join(result)\n",
    "\n",
    "\n",
    "def clean_repetition_in_summaries(summary_list, n=3):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ìš”ì•½ë¬¸ì— ëŒ€í•´ N-gram ë°˜ë³µì„ ì œê±°í•˜ëŠ” wrapper í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    cleaned_list = []\n",
    "    for text in summary_list:\n",
    "        cleaned = remove_repeated_ngrams(text, n=n)\n",
    "        \n",
    "        # ë‹¤ì¤‘ ê³µë°± ì •ë¦¬\n",
    "        cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "        cleaned_list.append(cleaned)\n",
    "\n",
    "    return cleaned_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… wandb ë¡œê·¸ì¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=\"624410f236117b79b2ee07a4ccef31c7514a5e03\")\n",
    "print(\"âœ… wandb ë¡œê·¸ì¸ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pandas version: 2.1.4\n",
      "âœ… torch version: 2.1.2+cu121\n",
      "âœ… transformers version: 4.35.2\n",
      "âœ… CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(\"âœ… pandas version:\", pd.__version__)\n",
    "print(\"âœ… torch version:\", torch.__version__)\n",
    "print(\"âœ… transformers version:\", __import__(\"transformers\").__version__)\n",
    "print(\"âœ… CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import wandb\n",
    "    WANDB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WANDB_AVAILABLE = False\n",
    "    print(\"âš ï¸ wandb not installed. Will run without experiment tracking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Qq46k6_CNQn"
   },
   "source": [
    "### 2) Config file ë§Œë“¤ê¸° (ì„ íƒ)\n",
    "- ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "  ë”°ë¼ì„œ, ì½”ë“œ ìƒì—ì„œ ëª¨ë¸ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•  ìˆ˜ë„ ìˆì§€ë§Œ ë…ë¦½ì ì¸ ë§¤ê°œë³€ìˆ˜ ì •ë³´ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197,
     "referenced_widgets": [
      "e920dbc173c045d1a32143349f1dff8e",
      "58c794fb7ce543a39fdf66d757f6eeab",
      "8a6464a355f7464c989033965d418a8a",
      "3645438ace1f4596a8dbc157b48c1521",
      "58001a60eacc44d5b38a68648adccde4",
      "6f5fde5b0ac840a18bd5cc380e564ff6",
      "45187decb58b4ad39ad532259c6277e5",
      "2307c6dcbe0141acb5e61baae19cade7",
      "4747b668e2fa4ab58a449446f80030f5",
      "14f6c91d6c634379b498586c51e606e0",
      "08d05bc20a96432badd459e1ffaf868e",
      "5dfcf310ca9e4e2794076098a5d69cea",
      "3c284a826f6843f6aa47eacad478ac30",
      "6caedd60c6b747469c82930be1f95d6d",
      "64f2218f899d446393cfea44f206f0a6",
      "d068f541df3f438dbd5138863e64b2f2",
      "affff1d8a89e4c14955d1b2aa39ff1ab",
      "13651c09564a4337b8274c1cb436faa5",
      "3bcd6b6b956347b29e1efa20a1d00542",
      "2fd3d7bbcd6948d8904d33001f95ea03",
      "d22fbc2c5dbf422399e496c9b500025a",
      "775d8bbeceac4e2da4f21ab6235c89ed",
      "de1a3f7701c243839fe03b930a9b9e30",
      "ebc22683058a4f229c5588e52fc93536",
      "52095cc7087243ac916055e569fd22f3",
      "a15af9e8158f4903b9189f3d322a5ef3",
      "21d2e54b5a0a4f79973a512105da43eb",
      "083ea69907bb48d4a8fff919bac51aad",
      "2a190bda0b72407e9a953cd2104dd3b2",
      "c18f0e3bc35e44d9915c3f84cd282a26",
      "3a04e871b74b45d7bf02fd33bb103577",
      "ac00d6c2cf974b33a628acb3f1471316",
      "285007b45236478ca147c6df752c8da4"
     ]
    },
    "id": "gZOE9TInCQHJ",
    "outputId": "8ce58487-6199-408c-cb37-49af1e218bc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# config ì„¤ì •ì— tokenizer ëª¨ë“ˆì´ ì‚¬ìš©ë˜ë¯€ë¡œ ë¯¸ë¦¬ tokenizerë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"digit82/kobart-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "5vsACJI7CVb8"
   },
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"./data/\", # ëª¨ë¸ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„° ê²½ë¡œë¥¼ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "        \"model_name\": \"digit82/kobart-summarization\", # ë¶ˆëŸ¬ì˜¬ ëª¨ë¸ì˜ ì´ë¦„ì„ ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        \"output_dir\": \"./prediction/\" # ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê°’ì„ ì €ì¥í•  ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 512,\n",
    "        \"decoder_max_len\": 100,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # íŠ¹ì • ë‹¨ì–´ë“¤ì´ ë¶„í•´ë˜ì–´ tokenizationì´ ìˆ˜í–‰ë˜ì§€ ì•Šë„ë¡ special_tokensì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
    "        \"special_tokens\": ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"overwrite_output_dir\": True,\n",
    "        \"num_train_epochs\": 20,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"per_device_train_batch_size\": 8,\n",
    "        \"per_device_eval_batch_size\": 16,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"lr_scheduler_type\": 'cosine',\n",
    "        \"optim\": 'adamw_torch',\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"evaluation_strategy\": 'epoch',\n",
    "        \"save_strategy\": 'epoch',\n",
    "        \"save_total_limit\": 5,\n",
    "        \"fp16\": True,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"seed\": 42,\n",
    "        \"logging_dir\": \"./logs\",\n",
    "        \"logging_strategy\": \"epoch\",\n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 100,\n",
    "        \"do_train\": True,\n",
    "        \"do_eval\": True,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "        \"report_to\": \"wandb\" # (ì„ íƒ) wandbë¥¼ ì‚¬ìš©í•  ë•Œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    },\n",
    "    # (ì„ íƒ) wandb í™ˆí˜ì´ì§€ì— ê°€ì…í•˜ì—¬ ì–»ì€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"fc_bootcamp\",\n",
    "        \"project\": \"huggingface\",\n",
    "        \"name\": \"<run_id>\"\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_path\": \"model ckt path\", # ì‚¬ì „ í•™ìŠµì´ ì§„í–‰ëœ ëª¨ë¸ì˜ checkpointë¥¼ ì €ì¥í•  ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "        \"result_path\": \"./prediction/\",\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 100,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 32,\n",
    "        # ì •í™•í•œ ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•´ ì œê±°í•  ë¶ˆí•„ìš”í•œ ìƒì„± í† í°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm7ob25lHBkR"
   },
   "source": [
    "- ì°¸ê³ âœ…    \n",
    ": wandb ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  entity, project, nameë¥¼ ì§€ì •í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. wandb í™ˆí˜ì´ì§€ì— ê°€ì…í•œ í›„ ì–»ì€ ì •ë³´ë¥¼ ì…ë ¥í•˜ì—¬ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "REJybO5UCabF"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì˜ êµ¬ì„± ì •ë³´ë¥¼ YAML íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "config_path = \"config/config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Config saved at: config/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"config\", exist_ok=True)\n",
    "config_path = \"config/config.yaml\"\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "\n",
    "print(\"âœ… Config saved at:\", config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': './data/',\n",
      "             'model_name': 'digit82/kobart-summarization',\n",
      "             'output_dir': './prediction/'},\n",
      " 'inference': {'batch_size': 32,\n",
      "               'ckt_path': 'model ckt path',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 100,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': '<s>',\n",
      "               'decoder_max_len': 100,\n",
      "               'encoder_max_len': 512,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#PassportNumber#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 100,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 20,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 16,\n",
      "              'per_device_train_batch_size': 8,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'fc_bootcamp',\n",
      "           'name': '<run_id>',\n",
      "           'project': 'huggingface'}}\n",
      "âœ… model_name: digit82/kobart-summarization\n",
      "âœ… data_path : ./data/\n",
      "âœ… bos_token: <s>\n",
      "âœ… special_tokens: ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']\n"
     ]
    }
   ],
   "source": [
    "with open(config_path, \"r\") as f:\n",
    "    loaded_config = yaml.safe_load(f)\n",
    "\n",
    "pprint(loaded_config)\n",
    "print(\"âœ… model_name:\", loaded_config[\"general\"][\"model_name\"])\n",
    "print(\"âœ… data_path :\", loaded_config[\"general\"][\"data_path\"])\n",
    "print(\"âœ… bos_token:\", loaded_config[\"tokenizer\"][\"bos_token\"])\n",
    "print(\"âœ… special_tokens:\", loaded_config[\"tokenizer\"][\"special_tokens\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë˜ vocab size: 30000\n",
      "ì¶”ê°€ special tokens: ['#Person1#', '#Person2#', '#Person3#', '#PhoneNumber#', '#Address#', '#PassportNumber#']\n"
     ]
    }
   ],
   "source": [
    "print(\"ì›ë˜ vocab size:\", tokenizer.vocab_size)\n",
    "print(\"ì¶”ê°€ special tokens:\", config_data[\"tokenizer\"][\"special_tokens\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObEASD6Wj6pl"
   },
   "source": [
    "### 3) Configuration ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JUBm_6RqlYpV",
    "outputId": "4b1c8c44-c6a9-40f1-adbd-72d48f0c983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': './data/',\n",
      "             'model_name': 'digit82/kobart-summarization',\n",
      "             'output_dir': './prediction/'},\n",
      " 'inference': {'batch_size': 32,\n",
      "               'ckt_path': 'model ckt path',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 100,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
      "               'result_path': './prediction/'},\n",
      " 'tokenizer': {'bos_token': '<s>',\n",
      "               'decoder_max_len': 100,\n",
      "               'encoder_max_len': 512,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#PassportNumber#']},\n",
      " 'training': {'do_eval': True,\n",
      "              'do_train': True,\n",
      "              'early_stopping_patience': 3,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'evaluation_strategy': 'epoch',\n",
      "              'fp16': True,\n",
      "              'generation_max_length': 100,\n",
      "              'gradient_accumulation_steps': 1,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './logs',\n",
      "              'logging_strategy': 'epoch',\n",
      "              'lr_scheduler_type': 'cosine',\n",
      "              'num_train_epochs': 20,\n",
      "              'optim': 'adamw_torch',\n",
      "              'overwrite_output_dir': True,\n",
      "              'per_device_eval_batch_size': 16,\n",
      "              'per_device_train_batch_size': 8,\n",
      "              'predict_with_generate': True,\n",
      "              'report_to': 'wandb',\n",
      "              'save_strategy': 'epoch',\n",
      "              'save_total_limit': 5,\n",
      "              'seed': 42,\n",
      "              'warmup_ratio': 0.1,\n",
      "              'weight_decay': 0.01},\n",
      " 'wandb': {'entity': 'fc_bootcamp',\n",
      "           'name': '<run_id>',\n",
      "           'project': 'huggingface'}}\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ config íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "config_path = \"config/config.yaml\"\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¨ config íŒŒì¼ì˜ ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRSbKEVslhwO",
    "outputId": "40ba5c67-574e-4f86-cbac-13e9f01c588a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': './data/',\n",
       " 'model_name': 'digit82/kobart-summarization',\n",
       " 'output_dir': './prediction/'}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‹¤í—˜ì— ì“°ì¼ ë°ì´í„°ì˜ ê²½ë¡œ, ì‚¬ìš©ë  ëª¨ë¸, ëª¨ë¸ì˜ ìµœì¢… ì¶œë ¥ ê²°ê³¼ë¥¼ ì €ì¥í•  ê²½ë¡œì— ëŒ€í•´ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['general']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ê³³ì— ì‚¬ìš©ìê°€ ì €ì¥í•œ ë°ì´í„° dir ì„¤ì •í•˜ê¸°\n",
    "# loaded_config['general']['data_path'] = \"data_path\"\n",
    "\n",
    "# evaluation_strategy -> eval_strategy ë³€í™˜ (transformers ë²„ì „ í˜¸í™˜ì„±)\n",
    "#if 'evaluation_strategy' in loaded_config['training']:\n",
    "#     loaded_config['training']['eval_strategy'] = loaded_config['training'].pop('evaluation_strategy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pvFmIOqljv1",
    "outputId": "958c9b06-90de-4872-b2fb-cf739a655b4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'decoder_max_len': 100,\n",
       " 'encoder_max_len': 512,\n",
       " 'eos_token': '</s>',\n",
       " 'special_tokens': ['#Person1#',\n",
       "  '#Person2#',\n",
       "  '#Person3#',\n",
       "  '#PhoneNumber#',\n",
       "  '#Address#',\n",
       "  '#PassportNumber#']}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•˜ê¸° ìœ„í•´ tokenization ê³¼ì •ì—ì„œ í•„ìš”í•œ ì •ë³´ë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEvwCIBVll-h",
    "outputId": "ca010ac3-05be-4983-d665-2a653f0ced0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do_eval': True,\n",
       " 'do_train': True,\n",
       " 'early_stopping_patience': 3,\n",
       " 'early_stopping_threshold': 0.001,\n",
       " 'evaluation_strategy': 'epoch',\n",
       " 'fp16': True,\n",
       " 'generation_max_length': 100,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'learning_rate': 1e-05,\n",
       " 'load_best_model_at_end': True,\n",
       " 'logging_dir': './logs',\n",
       " 'logging_strategy': 'epoch',\n",
       " 'lr_scheduler_type': 'cosine',\n",
       " 'num_train_epochs': 20,\n",
       " 'optim': 'adamw_torch',\n",
       " 'overwrite_output_dir': True,\n",
       " 'per_device_eval_batch_size': 16,\n",
       " 'per_device_train_batch_size': 8,\n",
       " 'predict_with_generate': True,\n",
       " 'report_to': 'wandb',\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_total_limit': 5,\n",
       " 'seed': 42,\n",
       " 'warmup_ratio': 0.1,\n",
       " 'weight_decay': 0.01}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ì´ í›ˆë ¨ ì‹œ ì ìš©ë  ë§¤ê°œë³€ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhqHf1njlnyg",
    "outputId": "be9519c6-118b-4e4f-ea11-4bcca0ac42bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity': 'fc_bootcamp', 'name': '<run_id>', 'project': 'huggingface'}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ê³¼ì •ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ëŠ” wandb ì„¤ì • ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['wandb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ì„ íƒ) ì´ê³³ì— ì‚¬ìš©ìê°€ ì‚¬ìš©í•  wandb config ì„¤ì •\n",
    "loaded_config['wandb']['entity'] = \"quriquri7\"\n",
    "loaded_config['wandb']['name'] = \"fc_bootcamp\"\n",
    "loaded_config['wandb']['project'] = \"nlp\"\n",
    "\n",
    "# wandb ë¹„í™œì„±í™” (ê¶Œí•œ ë¬¸ì œ í•´ê²°)\n",
    "loaded_config['training']['report_to'] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fm4gxPRVlppj",
    "outputId": "1342aa36-3934-4f73-c912-e7d35fe6df06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'ckt_path': 'model ckt path',\n",
       " 'early_stopping': True,\n",
       " 'generate_max_length': 100,\n",
       " 'no_repeat_ngram_size': 2,\n",
       " 'num_beams': 4,\n",
       " 'remove_tokens': ['<usr>', '<s>', '</s>', '<pad>'],\n",
       " 'result_path': './prediction/'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ì´ ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "loaded_config['inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš« wandb ë¹„í™œì„±í™” ìƒíƒœë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "USE_WANDB = loaded_config[\"training\"][\"report_to\"] == \"wandb\"\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.init(\n",
    "        entity=loaded_config['wandb']['entity'],\n",
    "        project=loaded_config['wandb']['project'],\n",
    "        name=loaded_config['wandb']['name'],\n",
    "    )\n",
    "    os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n",
    "    os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "else:\n",
    "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "    print(\"ğŸš« wandb ë¹„í™œì„±í™” ìƒíƒœë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ data_path: ./data/\n",
      "âœ… data_path ì¡´ì¬\n",
      "ğŸ“„ íŒŒì¼ ëª©ë¡: ['sample_submission.csv', 'train.csv', 'test.csv', 'dev.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = loaded_config[\"general\"][\"data_path\"]\n",
    "print(\"ğŸ“‚ data_path:\", data_path)\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"âŒ data_path ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âœ… data_path ì¡´ì¬\")\n",
    "    print(\"ğŸ“„ íŒŒì¼ ëª©ë¡:\", os.listdir(data_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” model_name: digit82/kobart-summarization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… model/tokenizer ë¡œë“œ ì„±ê³µ\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "model_name = loaded_config[\"general\"][\"model_name\"]\n",
    "print(\"ğŸ” model_name:\", model_name)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "mdl = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "print(\"âœ… model/tokenizer ë¡œë“œ ì„±ê³µ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2zt0b-8ogCL"
   },
   "source": [
    "### 4) ë°ì´í„° ë¶ˆëŸ¬ì™€ì„œ í™•ì¸í•´ë³´ê¸°\n",
    "- ì‹¤í—˜ì—ì„œ ì“°ì¼ ë°ì´í„°ë¥¼ loadí•˜ì—¬ ë°ì´í„°ì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "- Train, dev, test ìˆœì„œëŒ€ë¡œ 12457, 499, 250ê°œ ì”© ë°ì´í„°ê°€ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "QFHIE2G04y-K",
    "outputId": "19312d21-f5bf-495f-c626-cc17b82024a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>train_12455</td>\n",
       "      <td>#Person1#: ì•ˆë…•í•˜ì„¸ìš”. í˜¹ì‹œ ë§¨ì²´ìŠ¤í„°ì—ì„œ ì˜¤ì‹  Mr. Green ë§ìœ¼ì‹ ê°€ìš”...</td>\n",
       "      <td>Tan Lingì€ í°ë¨¸ë¦¬ì™€ ìˆ˜ì—¼ì´ íŠ¹ì§•ì¸ Mr. Greenì„ ë§ì´í•˜ì—¬ í˜¸í…”ë¡œ ì•ˆë‚´í•©...</td>\n",
       "      <td>í˜¸í…” ì•ˆë‚´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>train_12456</td>\n",
       "      <td>#Person1#: Mister Ewingì´ ìš°ë¦¬ íšŒì˜ì¥ì— 4ì‹œì— ì˜¤ë¼ê³  í–ˆì§€, ë§...</td>\n",
       "      <td>#Person1#ê³¼ #Person2#ëŠ” Mister Ewingì˜ ìš”ì²­ì— ë”°ë¼ íšŒì˜ì¥...</td>\n",
       "      <td>íšŒì˜ ì¤€ë¹„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>train_12457</td>\n",
       "      <td>#Person1#: ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\\n#Person2#: ì°¨ë¥¼ ë¹Œë¦¬ê³  ì‹¶...</td>\n",
       "      <td>#Person2#ëŠ” #Person1#ì˜ ë„ì›€ìœ¼ë¡œ 5ì¼ ë™ì•ˆ ì†Œí˜•ì°¨ë¥¼ ëŒ€ì—¬í•©ë‹ˆë‹¤.</td>\n",
       "      <td>ì°¨ëŸ‰ ëŒ€ì—¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12455</th>\n",
       "      <td>train_12458</td>\n",
       "      <td>#Person1#: ë„ˆ ì˜¤ëŠ˜ ì¢€ ê¸°ë¶„ ì•ˆ ì¢‹ì•„ ë³´ì¸ë‹¤? ë¬´ìŠ¨ ì¼ ìˆì–´?\\n#Pers...</td>\n",
       "      <td>#Person2#ì˜ ì–´ë¨¸ë‹ˆê°€ ì§ì¥ì„ ìƒìœ¼ì…¨ë‹¤. #Person2#ëŠ” ì–´ë¨¸ë‹ˆê°€ ìš°ìš¸í•´í•˜...</td>\n",
       "      <td>ì‹¤ì§ê³¼ ëŒ€ì²˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>train_12459</td>\n",
       "      <td>#Person1#: ì—„ë§ˆ, ë‚˜ ë‹¤ìŒ ì£¼ í† ìš”ì¼ì— ì´ëª¨ë¶€ë„¤ ê°€ì¡± ë³´ëŸ¬ ê°€ëŠ”ë°, ì˜¤ëŠ˜ ...</td>\n",
       "      <td>#Person1#ì€ ë‹¤ìŒ ì£¼ í† ìš”ì¼ì— ì´ëª¨ë¶€ë„¤ ê°€ì¡±ì„ ë°©ë¬¸í•˜ê¸° ìœ„í•´ ì§ì„ ì‹¸ì•¼ í•˜ëŠ”...</td>\n",
       "      <td>ê°€ì¡± ë°©ë¬¸ ì¤€ë¹„</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fname                                           dialogue  \\\n",
       "12452  train_12455  #Person1#: ì•ˆë…•í•˜ì„¸ìš”. í˜¹ì‹œ ë§¨ì²´ìŠ¤í„°ì—ì„œ ì˜¤ì‹  Mr. Green ë§ìœ¼ì‹ ê°€ìš”...   \n",
       "12453  train_12456  #Person1#: Mister Ewingì´ ìš°ë¦¬ íšŒì˜ì¥ì— 4ì‹œì— ì˜¤ë¼ê³  í–ˆì§€, ë§...   \n",
       "12454  train_12457  #Person1#: ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\\n#Person2#: ì°¨ë¥¼ ë¹Œë¦¬ê³  ì‹¶...   \n",
       "12455  train_12458  #Person1#: ë„ˆ ì˜¤ëŠ˜ ì¢€ ê¸°ë¶„ ì•ˆ ì¢‹ì•„ ë³´ì¸ë‹¤? ë¬´ìŠ¨ ì¼ ìˆì–´?\\n#Pers...   \n",
       "12456  train_12459  #Person1#: ì—„ë§ˆ, ë‚˜ ë‹¤ìŒ ì£¼ í† ìš”ì¼ì— ì´ëª¨ë¶€ë„¤ ê°€ì¡± ë³´ëŸ¬ ê°€ëŠ”ë°, ì˜¤ëŠ˜ ...   \n",
       "\n",
       "                                                 summary     topic  \n",
       "12452  Tan Lingì€ í°ë¨¸ë¦¬ì™€ ìˆ˜ì—¼ì´ íŠ¹ì§•ì¸ Mr. Greenì„ ë§ì´í•˜ì—¬ í˜¸í…”ë¡œ ì•ˆë‚´í•©...     í˜¸í…” ì•ˆë‚´  \n",
       "12453  #Person1#ê³¼ #Person2#ëŠ” Mister Ewingì˜ ìš”ì²­ì— ë”°ë¼ íšŒì˜ì¥...     íšŒì˜ ì¤€ë¹„  \n",
       "12454       #Person2#ëŠ” #Person1#ì˜ ë„ì›€ìœ¼ë¡œ 5ì¼ ë™ì•ˆ ì†Œí˜•ì°¨ë¥¼ ëŒ€ì—¬í•©ë‹ˆë‹¤.     ì°¨ëŸ‰ ëŒ€ì—¬  \n",
       "12455  #Person2#ì˜ ì–´ë¨¸ë‹ˆê°€ ì§ì¥ì„ ìƒìœ¼ì…¨ë‹¤. #Person2#ëŠ” ì–´ë¨¸ë‹ˆê°€ ìš°ìš¸í•´í•˜...    ì‹¤ì§ê³¼ ëŒ€ì²˜  \n",
       "12456  #Person1#ì€ ë‹¤ìŒ ì£¼ í† ìš”ì¼ì— ì´ëª¨ë¶€ë„¤ ê°€ì¡±ì„ ë°©ë¬¸í•˜ê¸° ìœ„í•´ ì§ì„ ì‹¸ì•¼ í•˜ëŠ”...  ê°€ì¡± ë°©ë¬¸ ì¤€ë¹„  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configì— ì €ì¥ëœ ë°ì´í„° ê²½ë¡œë¥¼ í†µí•´ trainê³¼ validation dataë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "data_path = loaded_config['general']['data_path']\n",
    "\n",
    "# train dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "train_df = pd.read_csv(os.path.join(data_path,'train.csv'))\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "FAGaYvNZ09Sq",
    "outputId": "bf8bf286-19e7-469d-ffae-41e6ad795ae6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>dev_495</td>\n",
       "      <td>#Person1#: ìƒˆí•´ê°€ ë˜ë‹ˆê¹Œ ë‚˜ë„ ìƒˆ ì¶œë°œì„ í•˜ê¸°ë¡œ í–ˆì–´.\\n#Person2#...</td>\n",
       "      <td>#Person1#ì€ ìƒˆí•´ì— ë‹´ë°°ë¥¼ ëŠê³  ì»¤ë°ì•„ì›ƒ í•˜ê¸°ë¡œ ê²°ì‹¬í–ˆìŠµë‹ˆë‹¤. #Person...</td>\n",
       "      <td>ìƒˆí•´ ê²°ì‹¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>dev_496</td>\n",
       "      <td>#Person1#: ë„ˆ Joeë‘ ê²°í˜¼í–ˆì§€?\\n#Person2#: Joe? ë¬´ìŠ¨ ë§ì´...</td>\n",
       "      <td>#Person1#ì€ #Person2#ê°€ Joeì™€ ê²°í˜¼í–ˆë‹¤ê³  ìƒê°í•˜ì§€ë§Œ, #Perso...</td>\n",
       "      <td>ì‚¬ë‘ê³¼ ê²°í˜¼ ì˜¤í•´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>dev_497</td>\n",
       "      <td>#Person1#: ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”, ì•„ì¤Œë§ˆ?\\n#Person2#: ì œ ì°¨ì—ì„œ ...</td>\n",
       "      <td>#Person2#ì˜ ì°¨ì—ì„œ ì†Œë¦¬ê°€ ë‚˜ë©°, ë¸Œë ˆì´í¬ ìˆ˜ë¦¬ê°€ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤. #Pe...</td>\n",
       "      <td>ì°¨ëŸ‰ ì†ŒìŒ ë° ìˆ˜ë¦¬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>dev_498</td>\n",
       "      <td>#Person1#: ì—¬ë³´ì„¸ìš”, ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\\n#...</td>\n",
       "      <td>#Person2#ê°€ ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì— ì „í™”í•˜ì—¬ ì•„ë§ˆì¡´ì—ì„œ êµ¬ë§¤í•œ ì±…ì— 53í˜ì´ì§€...</td>\n",
       "      <td>ì±… í˜ì´ì§€ ëˆ„ë½</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>dev_499</td>\n",
       "      <td>#Person1#: ë²Œì¨ ì—¬ë¦„ì´ ë‹¤ê°€ì˜¤ë‹¤ë‹ˆ ë¯¿ê¸°ì§€ ì•Šì•„. \\n#Person2#: ë§...</td>\n",
       "      <td>#Person2#ëŠ” ì—¬ë¦„ë°©í•™ ë™ì•ˆ íŒŒí‹°ì—ì„œ ì¼í•˜ëŠ” íšŒì‚¬ì—ì„œ ì¼í•˜ë©°, ì£¼ë¡œ ìŒì‹ ì¤€ë¹„...</td>\n",
       "      <td>ì—¬ë¦„ë°©í•™ ì¼ìë¦¬</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fname                                           dialogue  \\\n",
       "494  dev_495  #Person1#: ìƒˆí•´ê°€ ë˜ë‹ˆê¹Œ ë‚˜ë„ ìƒˆ ì¶œë°œì„ í•˜ê¸°ë¡œ í–ˆì–´.\\n#Person2#...   \n",
       "495  dev_496  #Person1#: ë„ˆ Joeë‘ ê²°í˜¼í–ˆì§€?\\n#Person2#: Joe? ë¬´ìŠ¨ ë§ì´...   \n",
       "496  dev_497  #Person1#: ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”, ì•„ì¤Œë§ˆ?\\n#Person2#: ì œ ì°¨ì—ì„œ ...   \n",
       "497  dev_498  #Person1#: ì—¬ë³´ì„¸ìš”, ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\\n#...   \n",
       "498  dev_499  #Person1#: ë²Œì¨ ì—¬ë¦„ì´ ë‹¤ê°€ì˜¤ë‹¤ë‹ˆ ë¯¿ê¸°ì§€ ì•Šì•„. \\n#Person2#: ë§...   \n",
       "\n",
       "                                               summary       topic  \n",
       "494  #Person1#ì€ ìƒˆí•´ì— ë‹´ë°°ë¥¼ ëŠê³  ì»¤ë°ì•„ì›ƒ í•˜ê¸°ë¡œ ê²°ì‹¬í–ˆìŠµë‹ˆë‹¤. #Person...       ìƒˆí•´ ê²°ì‹¬  \n",
       "495  #Person1#ì€ #Person2#ê°€ Joeì™€ ê²°í˜¼í–ˆë‹¤ê³  ìƒê°í•˜ì§€ë§Œ, #Perso...   ì‚¬ë‘ê³¼ ê²°í˜¼ ì˜¤í•´  \n",
       "496  #Person2#ì˜ ì°¨ì—ì„œ ì†Œë¦¬ê°€ ë‚˜ë©°, ë¸Œë ˆì´í¬ ìˆ˜ë¦¬ê°€ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤. #Pe...  ì°¨ëŸ‰ ì†ŒìŒ ë° ìˆ˜ë¦¬  \n",
       "497  #Person2#ê°€ ì•„ë§ˆì¡´ ê³ ê° ì„œë¹„ìŠ¤ì— ì „í™”í•˜ì—¬ ì•„ë§ˆì¡´ì—ì„œ êµ¬ë§¤í•œ ì±…ì— 53í˜ì´ì§€...    ì±… í˜ì´ì§€ ëˆ„ë½  \n",
       "498  #Person2#ëŠ” ì—¬ë¦„ë°©í•™ ë™ì•ˆ íŒŒí‹°ì—ì„œ ì¼í•˜ëŠ” íšŒì‚¬ì—ì„œ ì¼í•˜ë©°, ì£¼ë¡œ ìŒì‹ ì¤€ë¹„...    ì—¬ë¦„ë°©í•™ ì¼ìë¦¬  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation dataì˜ êµ¬ì¡°ì™€ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))\n",
    "val_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IIaIrpH4kWo"
   },
   "source": [
    "## 1. ë°ì´í„° ê°€ê³µ ë° ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬ì¶•\n",
    "- csv file ì„ ë¶ˆëŸ¬ì™€ì„œ encoder ì™€ decoderì˜ ì…ë ¥í˜•íƒœë¡œ ê°€ê³µí•´ì¤ë‹ˆë‹¤.\n",
    "- ê°€ê³µëœ ë°ì´í„°ë¥¼ torch dataset class ë¡œ êµ¬ì¶•í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "oWPawUUflwHa"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ë¡œ, ë°ì´í„°ì…‹ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ì…ë ¥ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "class Preprocess:\n",
    "    def __init__(self,\n",
    "            bos_token: str,\n",
    "            eos_token: str,\n",
    "        ) -> None:\n",
    "\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "\n",
    "    @staticmethod\n",
    "    # ì‹¤í—˜ì— í•„ìš”í•œ ì»¬ëŸ¼ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    def make_set_as_df(file_path, is_train = True):\n",
    "        if is_train:\n",
    "            df = pd.read_csv(file_path)\n",
    "            train_df = df[['fname','dialogue','summary']]\n",
    "            return train_df\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "            test_df = df[['fname','dialogue']]\n",
    "            return test_df\n",
    "\n",
    "    # BART ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥ í˜•íƒœë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    def make_input(self, dataset,is_test = False):\n",
    "        if is_test:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = [self.bos_token] * len(dataset['dialogue'])\n",
    "            return encoder_input.tolist(), list(decoder_input)\n",
    "        else:\n",
    "            encoder_input = dataset['dialogue']\n",
    "            decoder_input = dataset['summary'].apply(lambda x : self.bos_token + str(x)) # Ground truthë¥¼ ë””ì½”ë”ì˜ inputìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "            decoder_output = dataset['summary'].apply(lambda x : str(x) + self.eos_token)\n",
    "            return encoder_input.tolist(), decoder_input.tolist(), decoder_output.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "6GDvodoF8sED"
   },
   "outputs": [],
   "source": [
    "# Trainì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForTrain(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Validationì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForVal(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, labels, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.labels = labels\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()} # item[input_ids], item[attention_mask]\n",
    "        item2 = {key: val[idx].clone().detach() for key, val in self.decoder_input.items()} # item2[input_ids], item2[attention_mask]\n",
    "        item2['decoder_input_ids'] = item2['input_ids']\n",
    "        item2['decoder_attention_mask'] = item2['attention_mask']\n",
    "        item2.pop('input_ids')\n",
    "        item2.pop('attention_mask')\n",
    "        item.update(item2) #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask]\n",
    "        item['labels'] = self.labels['input_ids'][idx] #item[input_ids], item[attention_mask] item[decoder_input_ids], item[decoder_attention_mask], item[labels]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# Testì— ì‚¬ìš©ë˜ëŠ” Dataset í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class DatasetForInference(Dataset):\n",
    "    def __init__(self, encoder_input, test_id, len):\n",
    "        self.encoder_input = encoder_input\n",
    "        self.test_id = test_id\n",
    "        self.len = len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encoder_input.items()}\n",
    "        item['ID'] = self.test_id[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "hT9z4vvS2CCb"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "def prepare_train_dataset(config, preprocessor, data_path, tokenizer):\n",
    "    train_file_path = os.path.join(data_path,'train.csv')\n",
    "    val_file_path = os.path.join(data_path,'dev.csv')\n",
    "\n",
    "    # train, validationì— ëŒ€í•´ ê°ê° ë°ì´í„°í”„ë ˆì„ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "    train_data = preprocessor.make_set_as_df(train_file_path)\n",
    "    val_data = preprocessor.make_set_as_df(val_file_path)\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'train_data:\\n {train_data[\"dialogue\"][0]}')\n",
    "    print(f'train_label:\\n {train_data[\"summary\"][0]}')\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'val_data:\\n {val_data[\"dialogue\"][0]}')\n",
    "    print(f'val_label:\\n {val_data[\"summary\"][0]}')\n",
    "\n",
    "    encoder_input_train , decoder_input_train, decoder_output_train = preprocessor.make_input(train_data)\n",
    "    encoder_input_val , decoder_input_val, decoder_output_val = preprocessor.make_input(val_data)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    tokenized_encoder_inputs = tokenizer(encoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                            add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_inputs = tokenizer(decoder_input_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    tokenized_decoder_ouputs = tokenizer(decoder_output_train, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    train_inputs_dataset = DatasetForTrain(tokenized_encoder_inputs, tokenized_decoder_inputs, tokenized_decoder_ouputs,len(encoder_input_train))\n",
    "\n",
    "    val_tokenized_encoder_inputs = tokenizer(encoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_inputs = tokenizer(decoder_input_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "    val_tokenized_decoder_ouputs = tokenizer(decoder_output_val, return_tensors=\"pt\", padding=True,\n",
    "                        add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False)\n",
    "\n",
    "    val_inputs_dataset = DatasetForVal(val_tokenized_encoder_inputs, val_tokenized_decoder_inputs, val_tokenized_decoder_ouputs,len(encoder_input_val))\n",
    "\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "    return train_inputs_dataset, val_inputs_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5sKIJ5K5Pz1"
   },
   "source": [
    "## 2. Trainer ë° Trainingargs êµ¬ì¶•í•˜ê¸°\n",
    "- Huggingface ì˜ Trainer ì™€ Training argumentsë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "aQk8ILcEeGNz"
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•œ í‰ê°€ ì§€í‘œë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ë³¸ ëŒ€íšŒì—ì„œëŠ” ROUGE ì ìˆ˜ë¥¼ í†µí•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "def compute_metrics(config,tokenizer,pred):\n",
    "    rouge = Rouge()\n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    predictions[predictions == -100] = tokenizer.pad_token_id\n",
    "    labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, clean_up_tokenization_spaces=True)\n",
    "    labels = tokenizer.batch_decode(labels, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ë¶ˆí•„ìš”í•œ ìƒì„±í† í°ë“¤ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    replaced_predictions = decoded_preds.copy()\n",
    "    replaced_labels = labels.copy()\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    for token in remove_tokens:\n",
    "        replaced_predictions = [sentence.replace(token,\" \") for sentence in replaced_predictions]\n",
    "        replaced_labels = [sentence.replace(token,\" \") for sentence in replaced_labels]\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[0]}\")\n",
    "    print(f\"GOLD: {replaced_labels[0]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[1]}\")\n",
    "    print(f\"GOLD: {replaced_labels[1]}\")\n",
    "    print('-'*150)\n",
    "    print(f\"PRED: {replaced_predictions[2]}\")\n",
    "    print(f\"GOLD: {replaced_labels[2]}\")\n",
    "\n",
    "    # ìµœì¢…ì ì¸ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    results = rouge.get_scores(replaced_predictions, replaced_labels,avg=True)\n",
    "\n",
    "    # ROUGE ì ìˆ˜ ì¤‘ F-1 scoreë¥¼ í†µí•´ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "    result = {key: value[\"f\"] for key, value in results.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "RInkG8g-HjBi"
   },
   "outputs": [],
   "source": [
    "def build_training_args(config):\n",
    "    return Seq2SeqTrainingArguments(\n",
    "        output_dir=config['general']['output_dir'],\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=1,              # ğŸ”¥ ë°˜ë“œì‹œ 1ë¡œ ê°•ì œ\n",
    "        learning_rate=config['training']['learning_rate'],\n",
    "        per_device_train_batch_size=config['training']['per_device_train_batch_size'],\n",
    "        per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],\n",
    "        warmup_ratio=config['training']['warmup_ratio'],\n",
    "        weight_decay=config['training']['weight_decay'],\n",
    "        lr_scheduler_type=config['training']['lr_scheduler_type'],\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",              # ğŸ”¥ ìë™ checkpoint ì €ì¥ ê¸ˆì§€\n",
    "        load_best_model_at_end=False,    # ğŸ”¥ best model ìµœì‹  ë¡œë”© ê¸°ëŠ¥ ë”\n",
    "        logging_dir=config['training']['logging_dir'],\n",
    "        logging_strategy=\"epoch\",\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=config['training']['generation_max_length'],\n",
    "        fp16=True,\n",
    "        save_safetensors=True,\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ”¥ Trainer ìƒì„± í•¨ìˆ˜ (Trainer ìë™ ì €ì¥ ì™„ì „ ì°¨ë‹¨)\n",
    "# ============================================================\n",
    "\n",
    "def build_trainer(model, tokenizer, train_ds, val_ds, config):\n",
    "    training_args = build_training_args(config)\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred)\n",
    "    )\n",
    "\n",
    "    # ğŸ”¥ Trainer ê¸°ë³¸ save_model ê¸°ëŠ¥ ë¬´ë ¥í™” (shared weight error ë°©ì§€)\n",
    "    trainer.save_model = lambda *args, **kwargs: None\n",
    "\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ”¥ epochë³„ LoRA adapter ì €ì¥ í•¨ìˆ˜\n",
    "# ============================================================\n",
    "def save_lora_adapter(model, epoch):\n",
    "    save_dir = f\"./lora_epoch_{epoch}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.save_pretrained(save_dir)   # LoRA adapterë§Œ ì €ì¥ë¨\n",
    "    print(f\">>> Saved LoRA adapter: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ”¥ LoRA ì„¤ì • + ëª¨ë¸ì— LoRA ì ìš©í•˜ëŠ” í•¨ìˆ˜\n",
    "# ============================================================\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "def apply_lora_to_model(model):\n",
    "    \"\"\"\n",
    "    KoBARTì— LoRA ì£¼ì…\n",
    "    \"\"\"\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,                    # ë­í¬\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_2_SEQ_LM\",\n",
    "        target_modules=[\"q_proj\", \"v_proj\"]\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "KKWHe8dE5fSx"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ”¥ KoBART + LoRA ì ìš©ëœ ëª¨ë¸ ë¡œë” (êµì²´ ë²„ì „)\n",
    "# ============================================================\n",
    "\n",
    "def load_tokenizer_and_model_for_train(config, device):\n",
    "    print(\"---------- Load tokenizer & model with LoRA ----------\")\n",
    "\n",
    "    model_name = config['general']['model_name']\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # special tokens ì¶”ê°€\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': config['tokenizer']['special_tokens']})\n",
    "\n",
    "    # base BART model load\n",
    "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # ğŸ”¥ LoRA ì ìš©\n",
    "    model = apply_lora_to_model(model)\n",
    "    model.to(device)\n",
    "\n",
    "    print(\">>> ìµœì¢… ëª¨ë¸ config:\\n\", model.config)\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvutzKQYvQgl"
   },
   "source": [
    "## 3. ëª¨ë¸ í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZUb-BC42J-"
   },
   "source": [
    "- ì•ì—ì„œ êµ¬ì¶•í•œ í´ë˜ìŠ¤ ë° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "qnA96wmR44is"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ğŸ”¥ main(): ì •ìƒ ë‹¤ì¤‘ epoch + epochë³„ LoRA ì €ì¥\n",
    "# ============================================================\n",
    "\n",
    "def main(config):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"---------- device:\", device, \"----------\")\n",
    "    print(torch.__version__)\n",
    "\n",
    "    # 1) ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    model, tokenizer = load_tokenizer_and_model_for_train(config, device)\n",
    "\n",
    "    # 2) ë°ì´í„° ë¡œë“œ\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "    train_ds, val_ds = prepare_train_dataset(config, preprocessor, config['general']['data_path'], tokenizer)\n",
    "\n",
    "    # 3) Trainer ìƒì„±\n",
    "    trainer = build_trainer(model, tokenizer, train_ds, val_ds, config)\n",
    "\n",
    "    # ğŸ”¥ ì›í•˜ëŠ” epoch ìˆ˜\n",
    "    TOTAL_EPOCH = config['training']['num_train_epochs']\n",
    "\n",
    "    for epoch in range(TOTAL_EPOCH):\n",
    "        print(f\"\\n\\nğŸ”¥ğŸ”¥ğŸ”¥ EPOCH {epoch+1}/{TOTAL_EPOCH} ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\")\n",
    "\n",
    "        trainer.train()\n",
    "        print(f\"ğŸ”¥ Epoch {epoch+1} ì¢…ë£Œ\")\n",
    "\n",
    "        # ğŸ”¥ LoRA adapter ì €ì¥\n",
    "        save_lora_adapter(model, epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DMS60wL-Dhv",
    "outputId": "cbb6aba7-18ff-4d12-b9e7-2a2ef31d94d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device: cuda ----------\n",
      "2.1.2+cu121\n",
      "---------- Load tokenizer & model with LoRA ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 442,368 || all params: 124,306,944 || trainable%: 0.3559\n",
      ">>> ìµœì¢… ëª¨ë¸ config:\n",
      " BartConfig {\n",
      "  \"_name_or_path\": \"digit82/kobart-summarization\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.1,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"do_blenderbot_90_layernorm\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 2,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 1026,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 3,\n",
      "  \"scale_embedding\": false,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30006\n",
      "}\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "train_data:\n",
      " #Person1#: ì•ˆë…•í•˜ì„¸ìš”, Mr. Smith. ì €ëŠ” Dr. Hawkinsì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë¬´ìŠ¨ ì¼ë¡œ ì˜¤ì…¨ì–´ìš”? \n",
      "#Person2#: ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ë ¤ê³  ì™”ì–´ìš”. \n",
      "#Person1#: ë„¤, 5ë…„ ë™ì•ˆ ê²€ì§„ì„ ì•ˆ ë°›ìœ¼ì…¨ë„¤ìš”. ë§¤ë…„ í•œ ë²ˆì”© ë°›ìœ¼ì…”ì•¼ í•´ìš”. \n",
      "#Person2#: ì•Œì£ . íŠ¹ë³„íˆ ì•„í”ˆ ë°ê°€ ì—†ìœ¼ë©´ êµ³ì´ ê°ˆ í•„ìš”ê°€ ì—†ë‹¤ê³  ìƒê°í–ˆì–´ìš”. \n",
      "#Person1#: ìŒ, ì‹¬ê°í•œ ì§ˆë³‘ì„ í”¼í•˜ë ¤ë©´ ë¯¸ë¦¬ ë°œê²¬í•˜ëŠ” ê²Œ ì œì¼ ì¢‹ê±°ë“ ìš”. ë³¸ì¸ì„ ìœ„í•´ì„œë¼ë„ ë§¤ë…„ í•œ ë²ˆì€ ì˜¤ì„¸ìš”. \n",
      "#Person2#: ì•Œê² ìŠµë‹ˆë‹¤. \n",
      "#Person1#: ì—¬ê¸° ì¢€ ë³¼ê¹Œìš”. ëˆˆê³¼ ê·€ëŠ” ê´œì°®ìœ¼ì‹œë„¤ìš”. ê¹Šê²Œ ìˆ¨ í•œ ë²ˆ ì‰¬ì–´ë³´ì„¸ìš”. Mr. Smith, ë‹´ë°° í”¼ìš°ì„¸ìš”? \n",
      "#Person2#: ë„¤. \n",
      "#Person1#: ë‹´ë°°ê°€ íì•”í•˜ê³  ì‹¬ì¥ë³‘ì˜ ì£¼ëœ ì›ì¸ì¸ ê±° ì•„ì‹œì£ ? ëŠìœ¼ì…”ì•¼ í•´ìš”. \n",
      "#Person2#: ìˆ˜ë°± ë²ˆ ì‹œë„í–ˆëŠ”ë°, ë„ì €íˆ ìŠµê´€ì´ ì•ˆ ëŠì–´ì ¸ìš”. \n",
      "#Person1#: ìŒ, ë„ì›€ ë ë§Œí•œ ìˆ˜ì—…ê³¼ ì•½ë¬¼ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ê°€ì‹œê¸° ì „ì— ë” ì •ë³´ë¥¼ ë“œë¦´ê²Œìš”. \n",
      "#Person2#: ë„¤, ê³ ë§™ìŠµë‹ˆë‹¤, ì˜ì‚¬ ì„ ìƒë‹˜.\n",
      "train_label:\n",
      " Mr. SmithëŠ” Dr. Hawkinsì—ê²Œ ê±´ê°•ê²€ì§„ì„ ë°›ìœ¼ëŸ¬ ì™€ì„œ, ë§¤ë…„ ê²€ì§„ í•„ìš”ì„±ì„ ì•ˆë‚´ë°›ê³  í¡ì—° ìŠµê´€ ê°œì„ ì„ ìœ„í•œ ë„ì›€ì„ ì œì•ˆë°›ì•˜ìŠµë‹ˆë‹¤.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "val_data:\n",
      " #Person1#: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?\n",
      "#Person2#: ìš”ì¦˜ ìˆ¨ì‰¬ê¸°ê°€ í˜ë“¤ì–´ìš”.\n",
      "#Person1#: ìµœê·¼ì— ê°ê¸°ì— ê±¸ë ¸ë‚˜ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, ê°ê¸°ëŠ” ì•ˆ ê±¸ë ¸ì–´ìš”. ìˆ¨ì‰´ ë•Œ ê°€ìŠ´ì´ ë‹µë‹µí•´ìš”.\n",
      "#Person1#: í˜¹ì‹œ ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸° ìˆìœ¼ì„¸ìš”?\n",
      "#Person2#: ì•„ë‹ˆìš”, íŠ¹ë³„íˆ ì•Œê³  ìˆëŠ” ì•Œë ˆë¥´ê¸°ëŠ” ì—†ì–´ìš”.\n",
      "#Person1#: ì´ê²Œ í•­ìƒ ê·¸ëŸ°ê°€ìš”, ì•„ë‹ˆë©´ ì£¼ë¡œ í™œë™í•  ë•Œ ê·¸ëŸ°ê°€ìš”?\n",
      "#Person2#: ìš´ë™í•  ë•Œ íŠ¹íˆ ë§ì´ ê·¸ë˜ìš”.\n",
      "#Person1#: ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œëŠ” ê²Œ ì¢‹ê² ì–´ìš”.\n",
      "#Person2#: ë„ì™€ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤, ì˜ì‚¬ ì„ ìƒë‹˜.\n",
      "val_label:\n",
      " #Person2#ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2#ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.\n",
      "---------- Load data complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  deprecated_dl_args[\"use_seedable_sampler\"] = use_seedable_sampler\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Make dataset complete ----------\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 1/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 02:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.021200</td>\n",
       "      <td>4.494522</td>\n",
       "      <td>0.119112</td>\n",
       "      <td>0.019881</td>\n",
       "      <td>0.116010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    ê°#Person2##Person2#ì€ ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ê°ê¸°ì— ê±¸ë ¸ë‹¤ë©´ ê°ê¸°ì— ê±¸ë ¸ë‹¤ë©´ ê°ê¸°ì— ê±¸ë ¸ë‹¤ê³  ë§í•˜ë©°, ê°ê¸°ì— ê±¸ë ¸ë‹¤ë©´ ê°ê¸°ì— ê±¸ë ¸ë‹¤ê³  ë§í•˜ë©°, ê°ê¸°ì— ê±¸ë ¸ë‹¤ë©´ ê°ê¸°ì— ê±¸ë ¸ë‹¤ê³  ë§í•©ë‹ˆë‹¤.                                                   \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:    #Person2##Person2#ì€  3ì‹œ 30ë¶„  ì²´ìœ¡ê´€ì—ì„œ                                                                                        \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   íƒ±#Person2##Person2#(ê¸°ì]ê¸°ì]ê¸°ì]ê¸°ì]ê¸°ì] ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ ëª¨ê¸ˆ \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 1 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_1\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 2/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 02:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.279200</td>\n",
       "      <td>4.106964</td>\n",
       "      <td>0.222655</td>\n",
       "      <td>0.039293</td>\n",
       "      <td>0.213527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ”#Person2# ê°€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.                                                                                 \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì•¼ Jimmyê°€ #Person1#ì—ê²Œ #Person1#ì—ê²Œ                                                                                       \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€#Person1# ëŠ” ìµœê·¼ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ë“¤ì„ ë¨¹ìœ¼ë ¤ê³  í•©ë‹ˆë‹¤.                                                                                      \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 2 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_2\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 3/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 02:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.082400</td>\n",
       "      <td>4.006255</td>\n",
       "      <td>0.256467</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>0.244719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ëŠ”ë°, ê°ê¸°ì— ê±¸ë ¸ë‹¤ê³  ìƒê°í•˜ì§€ë§Œ ì˜ì‚¬ ì„ ìƒë‹˜ì€ ê°ê¸°ì— ê±¸ë¦¬ì§€ ì•Šì•˜ë‹¤ê³  ë§í•©ë‹ˆë‹¤.                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   ì•¼ Jmp#Person1# ì€ #Person1# ê³¼ í•¨ê»˜ #Person1# ì˜ ë„ì›€ì„ ë°›ì•„  3ì‹œ 30ë¶„ ìš´ë™ì— ì°¸ì—¬í•˜ê¸°ë¡œ ê²°ì •í–ˆë‹¤. #Person1# ì€ #Person1# ì˜ ë„ì›€ì„ ë°›ì•„  3ì‹œ 30ë¶„ ìš´ë™ì— ì°¸ì—¬í•˜ê¸°ë¡œ ê²°ì •í–ˆë‹¤. #Person1# ì€ #Person1# ì˜ ë„ì›€ì„ ë°›ì•„  3ì‹œ 30ë¶„ ìš´ë™ì— ì°¸ì—¬í•˜ê¸°ë¡œ ê²°ì •í–ˆë‹¤. #Person1# ì€ #Person1# ì˜ ë„ì›€ì„ ë°›ì•„  3ì‹œ 30ë¶„ ìš´ë™ì— ì°¸ì—¬í•˜ê¸°ë¡œ ê²°ì •í–ˆë‹¤.                        \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ëŠ” ê±´ê°•í•˜ê²Œ ë¨¹ìœ¼ë ¤ê³  í•©ë‹ˆë‹¤.                                                                                         \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 3 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_3\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 4/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.002900</td>\n",
       "      <td>3.956095</td>\n",
       "      <td>0.279454</td>\n",
       "      <td>0.072773</td>\n",
       "      <td>0.264346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤.                                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ì˜¤ëŠ˜ ì˜¤í›„ 3ì‹œ 30ë¶„ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤.                                                                                   \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ëŠ” ê±´ê°•í•˜ê²Œ ë¨¹ê¸° ìœ„í•´ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                                                                \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 4 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_4\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 5/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.958700</td>\n",
       "      <td>3.927649</td>\n",
       "      <td>0.289212</td>\n",
       "      <td>0.075066</td>\n",
       "      <td>0.273029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤.                                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” ì˜¤ëŠ˜ ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ í–ˆìœ¼ë©°, #Person2# ëŠ” #Person2# ê°€ ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ í–ˆë‹¤.                                                                            \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìœ¼ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                                                 \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 5 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_5\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 6/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.930900</td>\n",
       "      <td>3.909295</td>\n",
       "      <td>0.293711</td>\n",
       "      <td>0.077322</td>\n",
       "      <td>0.277608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤.                                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” ì˜¤ëŠ˜ ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ í–ˆìœ¼ë‚˜, #Person2# ëŠ” #Person2# ì—ê²Œ ì—ê²Œ #Person2# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤.                                                                     \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìœ¼ë¼ê³  ê¶Œí•©ë‹ˆë‹¤.                                                                                 \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 6 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_6\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 7/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 02:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.911200</td>\n",
       "      <td>3.896035</td>\n",
       "      <td>0.299491</td>\n",
       "      <td>0.081368</td>\n",
       "      <td>0.282659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤.                                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” ì˜¤ëŠ˜ ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ í–ˆìœ¼ë‚˜, #Person2# ëŠ” #Person2# ì—ê²Œ ì—ê²Œ #Person2# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤.                                                                     \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                                                                       \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 7 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_7\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 8/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.897400</td>\n",
       "      <td>3.885994</td>\n",
       "      <td>0.306424</td>\n",
       "      <td>0.082460</td>\n",
       "      <td>0.286750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤.                                                                                            \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” ì˜¤ëŠ˜ ìš´ë™í•˜ëŸ¬ ê°€ê¸°ë¡œ í–ˆìœ¼ë‚˜, #Person2# ëŠ” #Person2# ì—ê²Œ ì—ê²Œ #Person2# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤.                                                                     \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ê³ , ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                                                                  \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 8 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_8\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 9/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:59, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.886500</td>\n",
       "      <td>3.877901</td>\n",
       "      <td>0.316061</td>\n",
       "      <td>0.091031</td>\n",
       "      <td>0.295009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  í•©ë‹ˆë‹¤.                                                                             \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ #Person2# ì˜ ìš´ë™ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                                                                    \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ê³ , #Person1# ì€ ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                                                               \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 9 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_9\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 10/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.876400</td>\n",
       "      <td>3.871331</td>\n",
       "      <td>0.320056</td>\n",
       "      <td>0.092974</td>\n",
       "      <td>0.299236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  í•©ë‹ˆë‹¤.                                                                             \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                                                       \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ê³ , ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                                                                  \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 10 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_10\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 11/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.869300</td>\n",
       "      <td>3.865689</td>\n",
       "      <td>0.325463</td>\n",
       "      <td>0.098673</td>\n",
       "      <td>0.305685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  í•©ë‹ˆë‹¤.                                                                             \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                                                       \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ê³ , #Person1# ì€ ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                                                               \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 11 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_11\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 12/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.862800</td>\n",
       "      <td>3.860726</td>\n",
       "      <td>0.325625</td>\n",
       "      <td>0.095760</td>\n",
       "      <td>0.303501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ìŠµë‹ˆë‹¤. #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  í•©ë‹ˆë‹¤.                                                                             \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•œë‹¤. #Person2# ëŠ” #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•œë‹¤.                                                                        \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ê³ , #Person1# ì€ ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                                                               \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 12 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_12\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 13/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.856900</td>\n",
       "      <td>3.856869</td>\n",
       "      <td>0.325177</td>\n",
       "      <td>0.097713</td>\n",
       "      <td>0.306160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì‹œê¸°ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.                                          \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ê³ , #Person1# ì€ ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                           \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 13 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_13\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 14/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.852500</td>\n",
       "      <td>3.852909</td>\n",
       "      <td>0.326399</td>\n",
       "      <td>0.098141</td>\n",
       "      <td>0.305819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì„¸ìš”.                                                                                 \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                                                    \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ì¦ê²¨ ë¨¹ìŠµë‹ˆë‹¤. #Person1# ì€ ê³¼ì¼ì´ ê±´ê°•ì— ì¢‹ë‹¤ê³  ë§í•©ë‹ˆë‹¤.                                                                             \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 14 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_14\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 15/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.847000</td>\n",
       "      <td>3.849774</td>\n",
       "      <td>0.330587</td>\n",
       "      <td>0.099546</td>\n",
       "      <td>0.310980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ì„¸ìš”.                                         \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                            \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìœ¼ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                         \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 15 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_15\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 16/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.843400</td>\n",
       "      <td>3.846908</td>\n",
       "      <td>0.330343</td>\n",
       "      <td>0.100878</td>\n",
       "      <td>0.309766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                        \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê³¼ì¼ì´ë‘ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ê³ , #Person1# ì€ ë‹­ê³ ê¸°ë¥¼ ë¨¹ìŠµë‹ˆë‹¤.                                           \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 16 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_16\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 17/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.840600</td>\n",
       "      <td>3.844229</td>\n",
       "      <td>0.330019</td>\n",
       "      <td>0.102986</td>\n",
       "      <td>0.310593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                    \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                            \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìœ¼ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                         \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 17 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_17\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 18/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.837400</td>\n",
       "      <td>3.841979</td>\n",
       "      <td>0.328869</td>\n",
       "      <td>0.102607</td>\n",
       "      <td>0.310717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                             \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                     \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìœ¼ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                  \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 18 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_18\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 19/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.833900</td>\n",
       "      <td>3.839513</td>\n",
       "      <td>0.329901</td>\n",
       "      <td>0.102412</td>\n",
       "      <td>0.311566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                      \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                              \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìœ¼ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                           \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 19 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_19\n",
      "\n",
      "\n",
      "ğŸ”¥ğŸ”¥ğŸ”¥ EPOCH 20/20 ì‹œì‘ ğŸ”¥ğŸ”¥ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1558' max='1558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1558/1558 01:58, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge-1</th>\n",
       "      <th>Rouge-2</th>\n",
       "      <th>Rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.830600</td>\n",
       "      <td>3.837643</td>\n",
       "      <td>0.329404</td>\n",
       "      <td>0.102612</td>\n",
       "      <td>0.311077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person2# ëŠ” ê°ê¸°ì— ê±¸ë ¸ì§€ë§Œ, #Person1# ì€ ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³´ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                              \n",
      "GOLD: #Person2# ëŠ” ìˆ¨ì‰¬ê¸° ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ì˜ì‚¬ëŠ” #Person2# ì—ê²Œ ì¦ìƒì„ í™•ì¸í•˜ê³ , ì²œì‹ ê²€ì‚¬ë¥¼ ìœ„í•´ í ì „ë¬¸ì˜ì—ê²Œ ê°€ë³¼ ê²ƒì„ ê¶Œí•©ë‹ˆë‹¤.                                                                     \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:   JimmyëŠ” #Person1# ì—ê²Œ ìš´ë™í•˜ëŸ¬ ê°€ìê³  ì œì•ˆí•©ë‹ˆë‹¤. #Person2# ëŠ” #Person1# ì—ê²Œ #Person1# ì˜ ì£¼ê°„ ì¼ì •ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤.                                      \n",
      "GOLD: #Person1# ëŠ” Jimmyë¥¼ ìš´ë™í•˜ëŸ¬ ì´ˆëŒ€í•˜ê³  íŒ”ê³¼ ë³µê·¼ ìš´ë™ì„ í•˜ë„ë¡ ì„¤ë“í•©ë‹ˆë‹¤.                                                                                \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "PRED:  #Person1# ì€ #Person2# ì—ê²Œ ê³¼ì¼ê³¼ ì±„ì†Œ, ë‹­ê³ ê¸°ë¥¼ ë¨¹ìœ¼ë¼ê³  ê¶Œìœ í•©ë‹ˆë‹¤.                                                   \n",
      "GOLD: #Person1# ì€ ê±´ê°•ì— ì•ˆ ì¢‹ì€ ìŒì‹ì„ ê·¸ë§Œ ë¨¹ê¸°ë¡œ ê²°ì‹¬í•˜ê³ , #Person2# ëŠ” ìì‹ ì˜ ê±´ê°•í•œ ì‹ë‹¨ì„ #Person1# ì—ê²Œ ê³µìœ í•©ë‹ˆë‹¤.                                                                           \n",
      "ğŸ”¥ Epoch 20 ì¢…ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Saved LoRA adapter: ./lora_epoch_20\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cu121'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFtWqowCGzEc"
   },
   "source": [
    "## 4. ëª¨ë¸ ì¶”ë¡ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ê³³ì— ë‚´ê°€ ì‚¬ìš©í•  wandb config ì„¤ì •\n",
    "loaded_config['inference']['ckt_path'] = \"./lora_adapter_final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFGul3-rSscf"
   },
   "source": [
    "- test dataë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "lV1Do7nlTylG"
   },
   "outputs": [],
   "source": [
    "# tokenization ê³¼ì •ê¹Œì§€ ì§„í–‰ëœ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë  ë°ì´í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "def prepare_test_dataset(config,preprocessor, tokenizer):\n",
    "\n",
    "    test_file_path = os.path.join(config['general']['data_path'],'test.csv')\n",
    "\n",
    "    test_data = preprocessor.make_set_as_df(test_file_path,is_train=False)\n",
    "    test_id = test_data['fname']\n",
    "\n",
    "    print('-'*150)\n",
    "    print(f'test_data:\\n{test_data[\"dialogue\"][0]}')\n",
    "    print('-'*150)\n",
    "\n",
    "    encoder_input_test , decoder_input_test = preprocessor.make_input(test_data,is_test=True)\n",
    "    print('-'*10, 'Load data complete', '-'*10,)\n",
    "\n",
    "    test_tokenized_encoder_inputs = tokenizer(encoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['encoder_max_len'], return_token_type_ids=False,)\n",
    "    test_tokenized_decoder_inputs = tokenizer(decoder_input_test, return_tensors=\"pt\", padding=True,\n",
    "                    add_special_tokens=True, truncation=True, max_length=config['tokenizer']['decoder_max_len'], return_token_type_ids=False,)\n",
    "\n",
    "    test_encoder_inputs_dataset = DatasetForInference(test_tokenized_encoder_inputs, test_id, len(encoder_input_test))\n",
    "    print('-'*10, 'Make dataset complete', '-'*10,)\n",
    "\n",
    "    return test_data, test_encoder_inputs_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "eb49bLULT3aS"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "def load_lora_for_inference(base_model_name, lora_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "    model = BartForConditionalGeneration.from_pretrained(base_model_name)\n",
    "\n",
    "    model = PeftModel.from_pretrained(model, lora_path)\n",
    "    model.eval()\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "Axzu9rsoGLgJ"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì´ ìƒì„±í•œ ìš”ì•½ë¬¸ì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "def inference(config):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available()  else 'cpu')\n",
    "    print('-'*10, f'device : {device}', '-'*10,)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    generate_model , tokenizer = load_tokenizer_and_model_for_test_lora(config,device)\n",
    "\n",
    "    data_path = config['general']['data_path']\n",
    "    preprocessor = Preprocess(config['tokenizer']['bos_token'], config['tokenizer']['eos_token'])\n",
    "\n",
    "    test_data, test_encoder_inputs_dataset = prepare_test_dataset(config,preprocessor, tokenizer)\n",
    "    dataloader = DataLoader(test_encoder_inputs_dataset, batch_size=config['inference']['batch_size'])\n",
    "\n",
    "    summary = []\n",
    "    text_ids = []\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(dataloader):\n",
    "            text_ids.extend(item['ID'])\n",
    "            generated_ids = generate_model.generate(input_ids=item['input_ids'].to('cuda:0'),\n",
    "                            no_repeat_ngram_size=config['inference']['no_repeat_ngram_size'],\n",
    "                            early_stopping=config['inference']['early_stopping'],\n",
    "                            max_length=config['inference']['generate_max_length'],\n",
    "                            num_beams=config['inference']['num_beams'],\n",
    "                        )\n",
    "            for ids in generated_ids:\n",
    "                result = tokenizer.decode(ids)\n",
    "                summary.append(result)\n",
    "\n",
    "    # ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•˜ì—¬ ë…¸ì´ì¦ˆì— í•´ë‹¹ë˜ëŠ” ìŠ¤í˜ì…œ í† í°ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    remove_tokens = config['inference']['remove_tokens']\n",
    "    preprocessed_summary = clean_generated_summary(summary, remove_tokens)\n",
    "\n",
    "    # ğŸ”¥ ì¶”ê°€: ë°˜ë³µ ë¬¸ì¥ ì œê±°\n",
    "    preprocessed_summary = clean_repetition_in_summaries(preprocessed_summary, n=3)\n",
    "  \n",
    "\n",
    "    output = pd.DataFrame(\n",
    "        {\n",
    "            \"fname\": test_data['fname'],\n",
    "            \"summary\" : preprocessed_summary,\n",
    "        }\n",
    "    )\n",
    "    result_path = config['inference']['result_path']\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    output.to_csv(os.path.join(result_path, \"output.csv\"), index=False)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "-pJ1ZXf-5V50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- device : cuda:0 ----------\n",
      "2.1.2+cu121\n",
      "---------- Load tokenizer & LoRA model for inference ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/nlp_server/venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- LoRA inference model load complete ----------\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "test_data:\n",
      "#Person1#: Ms. Dawson, ë°›ì•„ì“°ê¸° ì¢€ ë¶€íƒë“œë ¤ì•¼ê² ì–´ìš”. \n",
      "#Person2#: ë„¤, ë§ì”€í•˜ì„¸ìš”... \n",
      "#Person1#: ì´ê±¸ ì˜¤ëŠ˜ ì˜¤í›„ê¹Œì§€ ëª¨ë“  ì§ì›ë“¤ì—ê²Œ ì‚¬ë‚´ ë©”ëª¨ë¡œ ë³´ë‚´ì•¼ í•´ìš”. ì¤€ë¹„ëë‚˜ìš”? \n",
      "#Person2#: ë„¤, ë§ì”€í•˜ì„¸ìš”. \n",
      "#Person1#: ëª¨ë“  ì§ì›ì—ê²Œ ì•Œë¦½ë‹ˆë‹¤... ì¦‰ì‹œ ë°œíš¨ë˜ì–´ ëª¨ë“  ì‚¬ë‚´ í†µì‹ ì€ ì´ë©”ì¼ê³¼ ê³µì‹ ë©”ëª¨ë¡œë§Œ ì œí•œë©ë‹ˆë‹¤. ê·¼ë¬´ ì‹œê°„ ë™ì•ˆ ì¦‰ì‹œ ë©”ì‹œì§€ í”„ë¡œê·¸ë¨ ì‚¬ìš©ì€ ê¸ˆì§€ë©ë‹ˆë‹¤. \n",
      "#Person2#: ì´ ì •ì±…ì´ ì‚¬ë‚´ í†µì‹ ì—ë§Œ ì ìš©ë˜ë‚˜ìš”, ì•„ë‹ˆë©´ ì™¸ë¶€ í†µì‹ ì—ë„ í•´ë‹¹ë˜ë‚˜ìš”? \n",
      "#Person1#: ì´ëŠ” ëª¨ë“  í†µì‹ ì— ì ìš©ë©ë‹ˆë‹¤. ì‚¬ë¬´ì‹¤ ë‚´ ì§ì› ê°„ í†µì‹  ë¿ë§Œ ì•„ë‹ˆë¼ ì™¸ë¶€ í†µì‹ ë„ í•´ë‹¹ë©ë‹ˆë‹¤. \n",
      "#Person2#: í•˜ì§€ë§Œ ë§ì€ ì§ì›ë“¤ì´ ê³ ê°ê³¼ ì†Œí†µí•˜ë ¤ê³  ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. \n",
      "#Person1#: í†µì‹  ë°©ë²•ì„ ë°”ê¿”ì•¼ í•  ê²ƒì…ë‹ˆë‹¤. ì´ ì‚¬ë¬´ì‹¤ì—ì„œëŠ” ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë„ˆë¬´ ë§ì€ ì‹œê°„ì´ ë‚­ë¹„ë©ë‹ˆë‹¤! ì´ì œ ê³„ì†í•´ì„œ ë©”ëª¨ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. ì–´ë””ê¹Œì§€ í–ˆì£ ? \n",
      "#Person2#: ë‚´ì™¸ë¶€ í†µì‹ ì— ì ìš©ë©ë‹ˆë‹¤. \n",
      "#Person1#: ë„¤. ì¦‰ì‹œ ë©”ì‹œì§€ë¥¼ ê³„ì† ì‚¬ìš©í•˜ë©´ ê²½ê³  í›„ ì‹œì • ì¡°ì¹˜ê°€ ì´ë£¨ì–´ì§€ë©°, ë‘ ë²ˆì§¸ ìœ„ë°˜ ì‹œ í•´ê³ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ì •ì±…ì— ê´€í•œ ì§ˆë¬¸ì€ ë¶€ì„œì¥ì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”. \n",
      "#Person2#: ê·¸ê²Œ ë‹¤ì¸ê°€ìš”? \n",
      "#Person1#: ë„¤. ì˜¤ëŠ˜ ì˜¤í›„ 4ì‹œê¹Œì§€ ì´ ë©”ëª¨ë¥¼ ì‘ì„±í•˜ê³  ë°°í¬í•´ì£¼ì„¸ìš”.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "---------- Load data complete ----------\n",
      "---------- Make dataset complete ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:18<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì˜ testë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "if __name__ == \"__main__\":\n",
    "    output = inference(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "OsPmLfhbzZqS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>Ms. Dawsonì€ ì´ë©”ì¼ê³¼ ê³µì‹ ë©”ëª¨ë§Œ ì œí•œí•˜ê³  ëª¨ë“  ì§ì›ì—ê²Œ ë©”ëª¨ë¥¼ ë°œì†¡í•œë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>Carrefour êµì°¨ë¡œ ê·¼ì²˜ì—ì„œ êµí†µì²´ì¦ì´ ì‹¬í•´ì§€ì #Person2# ëŠ” ëŒ€ì¤‘êµí†µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>Mashaì™€ Heroê°€ ë‘ ë‹¬ ë™ì•ˆ ë³„ê±° ì¤‘ì´ë”ë‹ˆ ê²°êµ­ ì´í˜¼ì„ ì‹ ì²­í–ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>Brianì€ ìƒì¼ ì¶•í•˜ íŒŒí‹°ì— ì°¸ì„í•  ì˜ˆì •ì´ë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>#Person1# ì€ #Person1# ì´ ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì— ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>test_495</td>\n",
       "      <td>#Person1# ì€ Charlieê°€ 6ì‹œì— ì•„ë¹ ë¥¼ ê³µí•­ì—ì„œ í”½ì—…í•˜ê¸° ìœ„í•´ ê²Œì„ì„ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>test_496</td>\n",
       "      <td>ë¼ë””ì˜¤ ë°©ì†¡êµ­ì—ì„œ ì¼í•˜ê²Œ ëœ #Person2# ëŠ” CBCì— ì œì•ˆí•˜ì—¬ Golden C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>test_497</td>\n",
       "      <td>AliceëŠ” ì„¸íƒê¸°ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ ê¸°ê³„ê°€ ë¹„ëˆ„ë¥¼ ë”°ë¡œ ë„£ì§€ ì•Šì•„ ë¶ˆí¸í•©ë‹ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>test_498</td>\n",
       "      <td>Mrsì™€ ThouëŠ” #Person1#ì—ê²Œ ì•„íŒŒíŠ¸ë¥¼ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ”ì§€ ë¬¼ì–´ë³´ê³  ë‹¤ì‹œ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>test_499</td>\n",
       "      <td>BetsyëŠ” íŒŒí‹°ì— ì´ˆëŒ€í•´ íŒŒí‹°ë¥¼ ì—´ë ¤ê³  í•©ë‹ˆë‹¤.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fname                                            summary\n",
       "0      test_0     Ms. Dawsonì€ ì´ë©”ì¼ê³¼ ê³µì‹ ë©”ëª¨ë§Œ ì œí•œí•˜ê³  ëª¨ë“  ì§ì›ì—ê²Œ ë©”ëª¨ë¥¼ ë°œì†¡í•œë‹¤.\n",
       "1      test_1  Carrefour êµì°¨ë¡œ ê·¼ì²˜ì—ì„œ êµí†µì²´ì¦ì´ ì‹¬í•´ì§€ì #Person2# ëŠ” ëŒ€ì¤‘êµí†µ...\n",
       "2      test_2           Mashaì™€ Heroê°€ ë‘ ë‹¬ ë™ì•ˆ ë³„ê±° ì¤‘ì´ë”ë‹ˆ ê²°êµ­ ì´í˜¼ì„ ì‹ ì²­í–ˆë‹¤.\n",
       "3      test_3                         Brianì€ ìƒì¼ ì¶•í•˜ íŒŒí‹°ì— ì°¸ì„í•  ì˜ˆì •ì´ë‹¤.\n",
       "4      test_4        #Person1# ì€ #Person1# ì´ ì˜¬ë¦¼í”½ ìŠ¤íƒ€ë””ì›€ì— ìˆë‹¤ê³  ë§í•©ë‹ˆë‹¤.\n",
       "..        ...                                                ...\n",
       "494  test_495  #Person1# ì€ Charlieê°€ 6ì‹œì— ì•„ë¹ ë¥¼ ê³µí•­ì—ì„œ í”½ì—…í•˜ê¸° ìœ„í•´ ê²Œì„ì„ ...\n",
       "495  test_496  ë¼ë””ì˜¤ ë°©ì†¡êµ­ì—ì„œ ì¼í•˜ê²Œ ëœ #Person2# ëŠ” CBCì— ì œì•ˆí•˜ì—¬ Golden C...\n",
       "496  test_497          AliceëŠ” ì„¸íƒê¸°ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ ê¸°ê³„ê°€ ë¹„ëˆ„ë¥¼ ë”°ë¡œ ë„£ì§€ ì•Šì•„ ë¶ˆí¸í•©ë‹ˆë‹¤.\n",
       "497  test_498  Mrsì™€ ThouëŠ” #Person1#ì—ê²Œ ì•„íŒŒíŠ¸ë¥¼ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ”ì§€ ë¬¼ì–´ë³´ê³  ë‹¤ì‹œ ...\n",
       "498  test_499                        BetsyëŠ” íŒŒí‹°ì— ì´ˆëŒ€í•´ íŒŒí‹°ë¥¼ ì—´ë ¤ê³  í•©ë‹ˆë‹¤.\n",
       "\n",
       "[499 rows x 2 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output  # ê° ëŒ€í™”ë¬¸ì— ëŒ€í•œ ìš”ì•½ë¬¸ì´ ì¶œë ¥ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "083ea69907bb48d4a8fff919bac51aad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d05bc20a96432badd459e1ffaf868e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13651c09564a4337b8274c1cb436faa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14f6c91d6c634379b498586c51e606e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21d2e54b5a0a4f79973a512105da43eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2307c6dcbe0141acb5e61baae19cade7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "285007b45236478ca147c6df752c8da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a190bda0b72407e9a953cd2104dd3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fd3d7bbcd6948d8904d33001f95ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3645438ace1f4596a8dbc157b48c1521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14f6c91d6c634379b498586c51e606e0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08d05bc20a96432badd459e1ffaf868e",
      "value": " 295/295 [00:00&lt;00:00, 21.3kB/s]"
     }
    },
    "3a04e871b74b45d7bf02fd33bb103577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcd6b6b956347b29e1efa20a1d00542": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c284a826f6843f6aa47eacad478ac30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_affff1d8a89e4c14955d1b2aa39ff1ab",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_13651c09564a4337b8274c1cb436faa5",
      "value": "tokenizer.json: 100%"
     }
    },
    "45187decb58b4ad39ad532259c6277e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4747b668e2fa4ab58a449446f80030f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52095cc7087243ac916055e569fd22f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c18f0e3bc35e44d9915c3f84cd282a26",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a04e871b74b45d7bf02fd33bb103577",
      "value": 109
     }
    },
    "58001a60eacc44d5b38a68648adccde4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c794fb7ce543a39fdf66d757f6eeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f5fde5b0ac840a18bd5cc380e564ff6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45187decb58b4ad39ad532259c6277e5",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "5dfcf310ca9e4e2794076098a5d69cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c284a826f6843f6aa47eacad478ac30",
       "IPY_MODEL_6caedd60c6b747469c82930be1f95d6d",
       "IPY_MODEL_64f2218f899d446393cfea44f206f0a6"
      ],
      "layout": "IPY_MODEL_d068f541df3f438dbd5138863e64b2f2"
     }
    },
    "64f2218f899d446393cfea44f206f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d22fbc2c5dbf422399e496c9b500025a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_775d8bbeceac4e2da4f21ab6235c89ed",
      "value": " 682k/682k [00:00&lt;00:00, 5.40MB/s]"
     }
    },
    "6caedd60c6b747469c82930be1f95d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcd6b6b956347b29e1efa20a1d00542",
      "max": 682133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2fd3d7bbcd6948d8904d33001f95ea03",
      "value": 682133
     }
    },
    "6f5fde5b0ac840a18bd5cc380e564ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "775d8bbeceac4e2da4f21ab6235c89ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a6464a355f7464c989033965d418a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2307c6dcbe0141acb5e61baae19cade7",
      "max": 295,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4747b668e2fa4ab58a449446f80030f5",
      "value": 295
     }
    },
    "a15af9e8158f4903b9189f3d322a5ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac00d6c2cf974b33a628acb3f1471316",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_285007b45236478ca147c6df752c8da4",
      "value": " 109/109 [00:00&lt;00:00, 9.44kB/s]"
     }
    },
    "ac00d6c2cf974b33a628acb3f1471316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "affff1d8a89e4c14955d1b2aa39ff1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c18f0e3bc35e44d9915c3f84cd282a26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d068f541df3f438dbd5138863e64b2f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22fbc2c5dbf422399e496c9b500025a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de1a3f7701c243839fe03b930a9b9e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebc22683058a4f229c5588e52fc93536",
       "IPY_MODEL_52095cc7087243ac916055e569fd22f3",
       "IPY_MODEL_a15af9e8158f4903b9189f3d322a5ef3"
      ],
      "layout": "IPY_MODEL_21d2e54b5a0a4f79973a512105da43eb"
     }
    },
    "e920dbc173c045d1a32143349f1dff8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58c794fb7ce543a39fdf66d757f6eeab",
       "IPY_MODEL_8a6464a355f7464c989033965d418a8a",
       "IPY_MODEL_3645438ace1f4596a8dbc157b48c1521"
      ],
      "layout": "IPY_MODEL_58001a60eacc44d5b38a68648adccde4"
     }
    },
    "ebc22683058a4f229c5588e52fc93536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_083ea69907bb48d4a8fff919bac51aad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a190bda0b72407e9a953cd2104dd3b2",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
